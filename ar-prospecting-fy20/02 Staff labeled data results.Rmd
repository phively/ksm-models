---
title: "02 Staff labeled data results"
output:
  html_notebook:
    toc: TRUE
    toc_float:
      collapsed: FALSE
---

# Goal

Quick analysis of the datasets labeled by staff, ultimately to create some sort of weighted training data set.

# Setup

```{r setup}
library(tidyverse)
library(wranglR)
library(readxl)
library(splines)
library(foreach)
```

```{r}
# Load master data
load(file = 'data/output/entities_modeled.Rdata')
```

```{r}
# Function to load and parse completed lists
parse_lists <- function(path) {
  files <- list.files(path)
  foreach(f = files, .combine = rbind, .multicombine = TRUE) %do% {
    # Load the data and extract contributor name
    data <- read_xlsx(path = paste0(path, '/', f), guess_max = 1E6)
    name <- str_match(f, '(?<=list for ).*(?=.xlsx)')
    data$name <- name
    # Keep only needed fields
    data %>%
      rename(Student = `Student Supporter?`, Connector = `Connector?`, Notable = `Notable?`, Interesting = `Interesting career/story`) %>%
      select(RANDOM_ID, name, Student, Connector, Notable, Interesting, Notes) %>%
      return()
  }
}

lists <- parse_lists(path = 'data/output/completed lists/')
```

# Initial exploration

```{r}
lists <- lists %>%
  mutate(
    across(.cols = name:Interesting, .fns = as.factor)
  )

lists %>% summary(maxsum = 1E3)
```

I can weight yes as 1, maybe as 0.5. Or just everything as 1?

```{r, rows.print = 100}
level_checker <- function(field) {
  lists %>%
    filter(!is.na({{ field }})) %>%
    group_by(name, {{ field}}) %>%
    summarise(n(), .groups = 'drop')
}
```

```{r, rows.print = 100}
level_checker(Student)
level_checker(Notable)
level_checker(Connector)
level_checker(Interesting)
```

Since all the possibles were from one person I'm inclined to treat them the same as yes.

```{r}
lists <- lists %>%
  mutate(
    across(.cols = Student:Interesting, .fns = function(x) {!is.na(x)})
  )
```

```{r}
lists %>% summary(maxsum = 1E3)
```

Finally, combine individual results back into the master data frame.

# Calibration names

A few people appeared on every list:

```{r}
calibration <- entities_modeled %>%
  left_join(
    lists
    , by = c('RANDOM_ID' = 'RANDOM_ID')
  ) %>%
  group_by(ID_NUMBER, RANDOM_ID, REPORT_NAME, INSTITUTIONAL_SUFFIX, quantile) %>%
  summarise(
    n = n()
    , student_supporter = sum(Student)
    , connector = sum(Connector)
    , notable = sum(Notable)
    , career = sum(Interesting)
    , .groups = 'drop'
  ) %>%
  filter(n > 1) %>%
  mutate(
    total = student_supporter + connector + notable + career
    , tag = case_when(
        quantile < .3 ~ '**'
        , quantile %>% between(.3, .7) ~ '+'
        , quantile > .7 ~ '--'
      )
  )
```

```{r, rows.print = 100}
calibration %>%
  select(-ID_NUMBER, -REPORT_NAME, -INSTITUTIONAL_SUFFIX, -n) %>%
  select(RANDOM_ID, quantile, tag, everything()) %>%
  arrange(desc(total))
```

Now that's interesting. People who are very interesting based on my initial (suspect) modeling process are consistently identified as such, while people in the middle or near the bottom are not easily identified.

Look at some of the data more in depth.

```{r}
entities_modeled %>%
  filter(RANDOM_ID %in% calibration$RANDOM_ID) %>%
  left_join(
    calibration %>% select(-ID_NUMBER, -REPORT_NAME, -INSTITUTIONAL_SUFFIX, -quantile, -n)
    , by = c('RANDOM_ID' = 'RANDOM_ID')
  ) %>%
  select(RANDOM_ID, quantile, student_supporter, connector, notable, career, total, tag, everything()) %>%
  arrange(desc(total)) %>%
  View()
```

Okay, it appears that the team is looking for indicators of engagement. If someone is completely unengaged, they are not being identified as someone who fits into one of the segments. I see both pros and cons to this approach.

# TO DO

- Correlation matrix showing agreement between raters
- Scoring based on % of time they agree with the majority vote?
- Weighted overall lists based on scoring
- Response variable as a 4-element vector? One per student supporter, connector, notable, career? Or just 0-4 ranking of estimated sum? (This assumes each type of alum is equally interesting)