---
title: "02 Cultivation score weights"
output:
  html_notebook:
    toc: TRUE
    toc_float:
      collapsed: FALSE
---

# Goal

Determine the extent to which each of the data elements related to the PG cultivation score (see [Ben Porter's Donor Cultivation Checklist](https://www.case.org/currents/x74757)) have impacted giving.

# Setup and datafile

```{r setup, message = FALSE, warning = FALSE}
library(tidyverse)
library(gridExtra)
library(e1071)
library(wranglR)
library(foreach)
library(splines)

# Functions adapted from previous analysis steps
source('code/functions.R')
```

The data file is generated with [this code](https://github.com/phively/ksm-models/blob/master/pg-cultivation-score-fy18/code/generate-data.R), adapted from the import data step of [01 Initial exploration.Rmd
](https://github.com/phively/ksm-models/blob/master/pg-cultivation-score-fy18/01%20Initial%20exploration.Rmd).

```{r}
filepath <- 'data/2018-07-26 PG scores for all active prospects.xlsx'
source('code/generate-data.R')
```

# Background {#background}

The following 12 items were able to be extracted from the database:

  * Alum or spouse of alum
  * Age
  * Chicago home address
  * Visited by prospect manager in last 2 years
  * 5+ total visits
  * Deep engagement (multiple family degrees, parent, season tickets, etc.)
  * High-level annual giving ($25K+)
  * High-level advisory board participation
  * Previous major gift ($250K+)
  * Meeting with president
  * Open proposal
  * Consistent donor (10+ years of giving, including 1+ of last 3)

Each counts as one point toward the cultivation score, which ranges from 0 to `r max(pool$CULTIVATION_SCORE) %>% I()`.

The context for this analysis is to look at how giving is related to the cultivation score. Consider the following two plots (replicated from [01 Initial exploration.Rmd
](https://github.com/phively/ksm-models/blob/master/pg-cultivation-score-fy18/01%20Initial%20exploration.Rmd)):

```{r, echo = FALSE, message = FALSE}
pool %>% filter(!is.na(CULTIVATION_SCORE) & CAMPAIGN_NEWGIFT_CMIT_CREDIT > 0) %>%
  scatterplotter(x = 'CULTIVATION_SCORE', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT'
    , color = 'MG_PR_MODEL_DESC', ytrans = 'log10', ylabels = scales::dollar) +
  scale_x_continuous(breaks = 0:18, minor_breaks = NULL) +
  labs(title = 'Cultivation score versus log10 campaign giving', x = 'PG cultivation score'
       , y = 'Campaign giving credit', color = 'MG prioritization model')
```

```{r, echo = FALSE, message = FALSE}
pool %>% filter(!is.na(CULTIVATION_SCORE)) %>%
  scatterplotter(x = 'CULTIVATION_SCORE', y = 'LARGEST_GIFT_OR_PAYMENT'
    , color = 'MG_PR_MODEL_DESC', ytrans = 'log10plus1', ylabels = scales::dollar) +
  scale_x_continuous(breaks = 0:18, minor_breaks = NULL) +
  labs(title = 'Cultivation score versus log10 largest gift', x = 'PG cultivation score'
       , y = 'Largest gift or pledge payment', color = 'MG prioritization model')
```

There is a nearly linear relationship between PG cultivation score and both campaign giving and an entity's largest gift or pledge payment. Fitting some sort of linear model will enhance our understanding of the various checklist items by estimating their relative impact.

# Data exploration

## Indicators

Look at how each of the factors are distributed.

```{r, rows.print = 100}
pool %>% select(
  ACTIVE_PROPOSALS, AGE, PM_VISIT_LAST_2_YRS, VISITS_5PLUS, AF_25K_GIFT, GAVE_IN_LAST_3_YRS
  , MG_250K_PLUS, PRESIDENT_VISIT, TRUSTEE_OR_ADVISORY_BOARD, Alumnus, DEEP_ENGAGEMENT
  , CHICAGO_HOME
) %>%
  gather('Variable', 'x', 1:12) %>%
  group_by(Variable) %>%
  summarise(pct.yes = mean(x), yes = sum(x), no = nrow(pool) - sum(x), n = nrow(pool)) %>%
  arrange(desc(pct.yes)) %>%
  mutate(pct.yes = scales::percent(pct.yes))
```

As expected, alumni status is far and away the leader. I'm a bit surprised that trustee and advisory board is as high as it is. MG and president visit are the least common factors. However, they still have hundreds of observations each so I don't see a reason to drop either.

## Underlying variables

Exploration of the underlying variables for the indicators (that were straightforward to compute). The blue lines indicate the mean, and the purple ones the median.

```{r}
# Function to produce a summary table, with higher order central moments
summary_moments <- function(x, name = NULL) {
  # Requires e1071 for the skewness and kurtosis functions
  suppressPackageStartupMessages(
    if (!require(e1071)) {
      stop('Requires installation of package e1071')
    }
  )
  # If no name passed use the name of x
  if (is.null(name)) {name <- quote(x) %>% deparse()}
  # Data frame to be returned
  data.frame(
    name = name
    , n = na.omit(x) %>% length()
    , min = min(x, na.rm = TRUE)
    , median = median(x, na.rm = TRUE)
    , mean = mean(x, na.rm = TRUE)
    , max = max(x, na.rm = TRUE)
    , sd = sd(x, na.rm = TRUE)
    , skewness = e1071::skewness(x, na.rm = TRUE)
    , kurtosis = e1071::kurtosis(x, na.rm = TRUE)
    , NAs = is.na(x) %>% sum()
  ) %>% return()
}

# Generic function to create histograms
histogrammer <- function(data, x, binwidth = 1, bins = NULL, color = NULL
                         , trans = 'identity', xbreak = waiver()) {
  vec <- paste0('data$', eval(x)) %>% parse(text = .) %>% eval()
  data %>%
    ggplot(aes_string(x = x, color = color)) +
    geom_histogram(binwidth = binwidth, bins = bins, alpha = .5) +
    geom_density(aes(y = ..count..), alpha = .5) +
    geom_vline(xintercept = mean(vec, na.rm = TRUE), color = 'blue', linetype = 'dashed') +
    geom_vline(xintercept = median(vec, na.rm = TRUE), color = 'purple', linetype = 'dotted') +
    scale_x_continuous(trans = trans, breaks = xbreak)
}
```

```{r}
pool %>% filter(!is.na(NUMERIC_AGE)) %>%
  histogrammer(x = 'NUMERIC_AGE', xbreak = seq(0, 200, by = 10)) +
  labs(title = 'Age')
```

```{r}
summary_moments(pool$NUMERIC_AGE, 'Age')
```

The age distribution is moderately right-skewed but looks fine. For a quick fix the NAs could be imputed as the group mean.

```{r}
pool %>%
  histogrammer(x = 'VISIT_COUNT') +
  labs(title = 'Visit count')
```

```{r}
summary_moments(pool$VISIT_COUNT, 'Visits')
```

It'd be sensible to transform the x axis or otherwise get rid of those outliers.

```{r}
pool %>%
  histogrammer(x = 'VISIT_COUNT', trans = 'sqrt', binwidth = NULL, bins = 200,
               xbreak = c(seq(0, 10, by = 2), seq(10, 100, by = 10), seq(100, 200, by = 20))) +
  labs(title = 'Sqrt visit, log10 count') +
  scale_y_continuous(trans = 'log10plus1', breaks = 10^(0:20))
```

Nearly a linear decrease in visit count on a log/sqrt scale - though I'm not sure how to interpret this.

```{r}
pool %>%
  histogrammer(x = 'YEARS_OF_GIVING') +
  labs(title = 'Years of giving')
```

```{r}
summary_moments(pool$YEARS_OF_GIVING, 'Years of giving')
```

This looks fine. There are more loyal donors than I would've thought.

```{r}
pool %>%
  histogrammer(x = 'YEARS_OF_GIVING_LAST_3') +
  labs(title = 'Years of giving last 3')
```

```{r}
summary_moments(pool$YEARS_OF_GIVING_LAST_3, 'Years of giving out of last 3')
```

Mostly nondonors, unsurprisingly.

```{r}
pool %>%
  histogrammer(x = 'MG_250K_COUNT') +
  labs(title = 'Count of $250K+ major gifts') +
  scale_y_continuous(trans = 'log10plus1', breaks = 10^(0:5), labels = 10^(0:5))
```

```{r}
summary_moments(pool$MG_250K_COUNT, '$250K+ major gifts')
```

```{r, rows.print = 100}
pool %>% group_by(MG_250K_COUNT) %>% mutate(n = 1) %>%
  summarise(
    total = sum(n)
    , proportion = {sum(n) / nrow(pool)} %>% scales::percent()
  )
```

Extremely few people make a single $250K+ gift, much less multiple ones.

```{r}
pool %>%
  histogrammer(x = 'SEASON_TICKET_YEARS', xbreak = seq(0, 20, by = 2)) +
  labs(title = 'Years holding season tickets') +
  scale_y_continuous(trans = 'log10plus1', breaks = 10^(0:20))
```

```{r}
summary_moments(pool$SEASON_TICKET_YEARS, 'Years holding season tickets')
```

That jump at 10 years is odd. Perhaps season tickets have only been consistently tracked for about 10 years?

## Underlying variable scatterplots

```{r}
pool %>% filter(!is.na(NUMERIC_AGE)) %>%
  scatterplotter(x = 'NUMERIC_AGE', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(NUMERIC_AGE)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Age versus campaign giving')
```

```{r}
pool %>% filter(!is.na(NUMERIC_AGE)) %>%
  scatterplotter(x = 'NUMERIC_AGE', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(NUMERIC_AGE)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Age versus largest gift')
```

As usual, age is positively associated with giving. The outlier `r pool$NUMERIC_AGE %>% max(na.rm = TRUE) %>% I()`-year-old should probably be removed.

```{r}
max_age <- 110
pool %>% filter(NUMERIC_AGE <= max_age) %>%
  scatterplotter(x = 'NUMERIC_AGE', y = 'LARGEST_GIFT_OR_PAYMENT'
                 , color = 'MG_PR_MODEL_DESC', ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(NUMERIC_AGE)), color = 'blue', linetype = 'dashed') +
  labs(title = bquote('Age versus largest gift' ~ (age <= .(max_age)) ))
```

For visits, based on the above exploration visit count needs a transformation.

```{r}
pool %>%
  scatterplotter(x = 'VISIT_COUNT', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(VISIT_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Log-sqrt visit count versus campaign giving') +
  scale_x_sqrt()
```

```{r}
pool %>%
  scatterplotter(x = 'VISIT_COUNT', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(VISIT_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Log-sqrt visit count versus largest gift') +
  scale_x_sqrt()
```

```{r}
pool %>%
  scatterplotter(x = 'VISIT_COUNT', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(VISIT_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Log-log visit count versus campaign giving') +
  scale_x_continuous(trans = 'log10plus1', breaks = c(0, 1, 10, 50, 100, 150, 200))
```

```{r}
pool %>%
  scatterplotter(x = 'VISIT_COUNT', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(VISIT_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Log-log visit count versus largest gift') +
  scale_x_continuous(trans = 'log10plus1', breaks = c(0, 1, 10, 50, 100, 150, 200))
```

The log-log plots look quite good. Visits $\geq$ 100 are outliers, but at first glance don't appear influential on the log-log scale (easy to test with e.g. Cook's D).

```{r}
pool %>%
  scatterplotter(x = 'YEARS_OF_GIVING', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(YEARS_OF_GIVING)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Years of giving versus campaign giving') +
  scale_x_sqrt()
```

```{r}
pool %>%
  scatterplotter(x = 'YEARS_OF_GIVING', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(YEARS_OF_GIVING)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Years of giving versus largest gift') +
  scale_x_sqrt()
```

The square root transformation does well for campaign giving, but not as well for largest gift or payment.

```{r}
# Box-Cox test for transformations
boxcox_lambdas <- seq(-1, 1, by = .01)
boxcox_lm <- lm(I(LARGEST_GIFT_OR_PAYMENT + 1) ~ YEARS_OF_GIVING, data = pool) %>%
  MASS::boxcox(lambda = boxcox_lambdas, plotit = FALSE)
maxLL <- boxcox_lm$x[which(boxcox_lm$y == max(boxcox_lm$y))]

# Plot results
boxcox_lm %>%
  unlist() %>%
  matrix(nrow = length(boxcox_lambdas)) %>%
  data.frame() %>%
  select(x = X1, y = X2) %>%
  ggplot(aes(x = x, y = y)) +
  geom_line() +
  geom_vline(aes(xintercept = x[which(y == max(y))]), color = 'blue', linetype = 'dashed') +
  labs(title = 'Box-Cox analysis', x = expression(lambda), y = 'log Likelihood')
```

$\lambda =$ `r maxLL %>% I()` is pretty close to a log transformation.

```{r}
# Best Box-Cox transformation, adding 1 so the response variable is strictly positive
boxcoxbest_trans <- function(x) {
  scales::trans_new(
    'boxcoxbest'
    , transform = function(x) {(x + 1)^maxLL}
    , inverse = function(x) {(x + 1)^(1/maxLL)}
  )
}
```

```{r}
grid.arrange(
# Plot Box-Cox results
  pool %>%
    scatterplotter(x = 'YEARS_OF_GIVING', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                   , ytrans = 'log10plus1', ylabels = scales::dollar) +
    geom_vline(aes(xintercept = mean(YEARS_OF_GIVING)), color = 'blue', linetype = 'dashed') +
    labs(title = 'Years of giving versus campaign giving, Box-Cox transformation', y = 'Largest gift') +
    scale_x_continuous(trans = 'boxcoxbest', breaks = c(0, 10))
# Plot log10 results
  , pool %>%
    scatterplotter(x = 'YEARS_OF_GIVING', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                   , ytrans = 'log10plus1', ylabels = scales::dollar) +
    geom_vline(aes(xintercept = mean(YEARS_OF_GIVING)), color = 'blue', linetype = 'dashed') +
    labs(title = 'Years of giving versus campaign giving, log transformation', y = 'Largest gift') +
    scale_x_continuous(trans = 'log10plus1')
)
```

After all that neither look linear, though they do look nearly linear around the mean.

```{r}
pool %>% mutate(last_3_yrs = factor(YEARS_OF_GIVING_LAST_3)) %>%
  ggplot(aes(x = last_3_yrs, y = CAMPAIGN_NEWGIFT_CMIT_CREDIT, color = MG_PR_MODEL_DESC)) +
  geom_boxplot() +
  facet_grid(. ~ MG_PR_MODEL_DESC) +
  scale_y_continuous(trans = 'log10plus1', labels = scales::dollar, breaks = 10^(0:20)) +
  labs(title = 'Years of giving of last 3 versus campaign giving')
```

```{r}
pool %>% mutate(last_3_yrs = factor(YEARS_OF_GIVING_LAST_3)) %>%
  ggplot(aes(x = last_3_yrs, y = LARGEST_GIFT_OR_PAYMENT, color = MG_PR_MODEL_DESC)) +
  geom_boxplot() +
  facet_grid(. ~ MG_PR_MODEL_DESC) +
  scale_y_continuous(trans = 'log10plus1', labels = scales::dollar, breaks = 10^(0:20)) +
  labs(title = 'Years of giving of last 3 versus largest gift')
```

I see a main effect for campaign giving.

```{r}
pool %>%
  scatterplotter(x = 'MG_250K_COUNT', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(MG_250K_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Count of $250K+ gifts versus campaign giving') +
  scale_x_sqrt()
```

```{r}
pool %>%
  scatterplotter(x = 'MG_250K_COUNT', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(MG_250K_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Count of $250K+ gifts versus largest gift') +
  scale_x_sqrt()
```

As seen above, pretty much all of the observations are outliers. Might make sense to leave this one discretized.

```{r}
pool %>%
  scatterplotter(x = 'SEASON_TICKET_YEARS', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(SEASON_TICKET_YEARS)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Season ticket years versus campaign giving') +
  scale_x_continuous(breaks = seq(0, 100, by = 2))
```

```{r}
pool %>%
  scatterplotter(x = 'SEASON_TICKET_YEARS', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(SEASON_TICKET_YEARS)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Season ticket years versus largest gift') +
  scale_x_continuous(breaks = seq(0, 100, by = 2))
```

This looks fine.

## Data exploration takeaways

  * Missing age values can be imputed as mean age
  * The 113-year-old is an outlier
  * Visit count could use log transform
  * Years of giving could use sqrt transform
  * $250K+ gifts is a binary indicator

# Modeling ground rules

I'll outline some basic methodology in advance of modeling to try to account for [researcher degrees of freedom](http://journals.sagepub.com/doi/full/10.1177/0956797611417632).

As seen above, both campaign giving and largest lifetime gift have a strong linear relationship with the cultivation score, formulated as a 0 to `r max(pool$CULTIVATION_SCORE) %>% I()` point scale. Currently, all criteria count as a single point (equally weighted) but I suspect they impact actual giving behavior differently. I propose four models:

  1) Linear regression of campaign giving on cultivation score variables
  2) Linear regression of campaign on all available explanatory variables, essentially looking at the cultivation score variables controlling for the preexisting modeled scores
  3) Linear regression of largest cash transaction on cultivation score variables
  4) Linear regression of largest cash transaction on all available explanatory variables, again to control for the preexisting modeled scores

If a given explanatory variable has the same coefficient sign and similar nonzero magnitudes in all models, I'll take this as evidence of an association with giving behavior.

After withholding a random 20% of the data as a test set, I'll use ten-fold cross-validation to determine which variables should be included in each model. Model performance will be determined based on out-of-sample mean squared error, defined as usual:

$$ {\text{MSE}} = \frac{1}{n} \sum_{i=1}^{n} \left( Y_i - \hat{Y}_i \right)^2 $$

The 20% test set will be used to confirm the cross-validation results, and then final models will be constructed on the entire dataset for comparison.

## Data cleanup

First, perform some quick data clean-up.

```{r}
mdat <- pool %>% mutate(
  # Impute missing ages as mean age
  NUMERIC_AGE = case_when(
    !is.na(NUMERIC_AGE) ~ NUMERIC_AGE
    , TRUE ~ mean(NUMERIC_AGE, na.rm = TRUE)
  )
  # Impute missing affinity scores as mean affinity score
  , AFFINITY_SCORE = case_when(
    !is.na(AFFINITY_SCORE) ~ AFFINITY_SCORE
    , TRUE ~ mean(AFFINITY_SCORE, na.rm = TRUE)
  )
  # Create null factor levels for the MG_ID and MG_PR models
  , MG_ID_MODEL_DESC = fct_explicit_na(MG_ID_MODEL_DESC, 'Unscored') %>% fct_relevel('Unscored')
  , MG_PR_MODEL_DESC = fct_explicit_na(MG_PR_MODEL_DESC, 'Unscored') %>% fct_relevel('Unscored')
) %>% select(
  # Drop unhelpful fields
  -ID_NUMBER, -PROSPECT_ID, -PROSPECT_NAME, -NU_DEG, -NU_DEG_SPOUSE, -POTENTIAL_INTEREST_AREAS
  , -PREF_NAME_SORT, -MG_ID_MODEL_YEAR, -MG_ID_MODEL_SCORE, -MG_PR_MODEL_YEAR, -MG_PR_MODEL_SCORE
)
```

I'll use my `wranglR::KFoldXVal` function to create the cross-validation groups.

```{r}
k <- 11
# Create k groups: first is 20% of the data (prop = .2) and the others are equally sized
xval_inds <- pool %>% wranglR::KFoldXVal(k = k, prop = .2, seed = 12644)
oos_inds <- xval_inds[[1]]
xval_inds <- xval_inds[2:k]
# Results
c(list(oos_inds), xval_inds) %>% summary
```

Group 1 is the out-of-sample validation set, and the other `r {k - 1} %>% I()` will be used for cross-validation.

Finally, I'll create a quick function to compute MSE.

```{r}
calc_mse <- function(y, yhat) {
  mean(
    (y - yhat)^2, na.rm = TRUE
  )
}
```

## Visualization functions

```{r}
# Create coefficients data frame
create_coefs <- function(model_list) {
  foreach(i = 1:length(model_list), .combine = 'rbind') %do% {
    tmp <- summary(model_list[[i]])$coefficients
    data.frame(tmp) %>%
    mutate(
      variable = rownames(tmp)
      , model = i
    ) %>% select(
      model
      , variable
      , beta.hat = Estimate
      , SE = Std..Error
      , t.val = t.value
      , Pr.t = Pr...t..
    ) %>% return()
  } %>% return()
}

# Plot R-squared
plot_r2 <- function(model_list, type = 'r.squared') {
  parser <- function(x) {
    tmpsum <- summary(x)
    paste0('tmpsum$', type) %>% parse(text = .) %>% eval() %>% return()
  }
  model_list %>%
  lapply(., function(x) parser(x)) %>% unlist() %>% data.frame(r.squared = .) %>%
    ggplot(aes(x = r.squared)) + 
    geom_density() +
    geom_vline(aes(xintercept = mean(r.squared)), color = 'blue', linetype = 'dashed', alpha = .5) +
    geom_rug(color = 'blue') +
    labs(title = bquote('Density plot of' ~ r^2 ~ 'results, mean' ~
        .(lapply(model_list, function(x) {summary(x)$r.squared}) %>% unlist() %>% mean() %>% round(3))
      )
      , x = bquote(r^2)
    )
}

# Plot cross-validated coefficients
plot_coefs <- function(model_list) {
  create_coefs(model_list) %>%
  ggplot(aes(x = variable, y = beta.hat, color = factor(model))) +
  geom_point() +
  geom_hline(yintercept = 0, alpha = .5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.title.y = element_text(angle = 0, vjust = .5)) +
  labs(
    title = 'Coefficient estimates per cross-validation model'
    , y = bquote(hat(beta))
    , color = 'cross-validation sample'
  )
}

# Table of coefficient +/- counts
coef_pm_table <- function(model_list, pval) {
  create_coefs(model_list) %>%
  group_by(variable) %>%
  summarise(
    `+` = sum(sign(beta.hat) == 1 & Pr.t < pval)
    , `0` = sum(Pr.t >= pval)
    , `-` = sum(sign(beta.hat) < 0 & Pr.t < pval)
  )
}

# Compute predictions
calc_preds <- function(model_list, xval, yname) {
  yhats <- list()
  for (i in 1:length(model_list)) {
    yhats[[i]] <- data.frame(
      model = i
      , row = xval[[i]]
      , preds = model_list[[i]] %>% predict(newdata = mdat[xval[[i]], ])
      , truth = mdat[xval[[i]], yname] %>% unlist() %>% log10plus1()
    )
  }
  return(yhats)
}
calc_outsample_mse <- function(model_list, xval, yname) {
  calc_preds(model_list, xval, yname) %>%
    lapply(function(x) calc_mse(y = x$truth, yhat = x$preds)) %>%
    unlist()
}

# Plot MSEs by insample/outsample
plot_mses <- function(model_list, xval, truth) {
  mses <- data.frame(
    insample = model_list %>%
      lapply(function(x) calc_mse(y = model.frame(x)[, 1], yhat = predict(x))) %>%
      unlist()
    , outsample = calc_outsample_mse(model_list, xval, truth)
  ) %>% gather('type', 'MSE', 1:2)
  mses %>%
    ggplot(aes(x = MSE, color = type)) +
    geom_density() +
    geom_vline(
      xintercept = mses %>% filter(type == 'insample') %>% select(MSE) %>% unlist %>% mean()
      , color = 'red', linetype = 'dashed', alpha = .5
    ) +
    geom_vline(
      xintercept = mses %>% filter(type == 'outsample') %>% select(MSE) %>% unlist %>% mean()
      , color = 'darkcyan', linetype = 'dashed', alpha = .5
    ) +
    geom_rug() +
    labs(
      title = bquote('MSE across samples, means =' ~
          .(mses %>% group_by(type) %>% summarise(mean = mean(MSE)) %>%
              select(mean) %>% unlist() %>% round(3) %>% paste(collapse = ', ')
          )
        )
    )
}

# Merges predicted results into one large data frame each for insample and outsample
calc_resids <- function(model_list, xval, yname) {
  insample <- foreach(i = 1:length(model_list), .combine = 'rbind') %do% {
    data.frame(
      model = i
      , preds = model_list[[i]] %>% predict()
      , truth = model.frame(model_list[[i]])[, 1]
    ) %>% mutate(
      residuals = truth - preds
    )
  }
  preds <- calc_preds(model_list, xval, yname)
  outsample <- foreach(i = 1:length(model_list), .combine = 'rbind') %do% {
    preds[[i]]
  } %>% mutate(
    residuals = truth - preds
  )
  return(list(insample = insample, outsample = outsample))
}

# Plot standardized residuals; returns a list of ggplot objects $insample and $outsample
plot_resids <- function(model_list, xval, yname, filter = 'TRUE') {
  resids <- calc_resids(model_list, xval, yname)
  # Plot residuals vs fitted for in-sample data
  insample <- resids$insample %>% mutate(residuals = truth - preds) %>% filter_(filter) %>%
    ggplot(aes(x = preds, y = residuals, color = factor(model))) +
    geom_point(alpha = .01) +
    geom_smooth(se = FALSE) +
    labs(title = 'In-sample residuals versus fitted', color = 'cross-validation sample')
  # Plot residuals vs fitted for out-of-sample data
  outsample <- resids$outsample %>% mutate(residuals = truth - preds) %>%
    ggplot(aes(x = preds, y = residuals, color = factor(model))) +
    geom_point(alpha = .1) +
    geom_smooth(se = FALSE) +
    labs(title = 'Out-of-sample residuals versus fitted', color = 'cross-validation sample')
  return(list(insample = insample, outsample = outsample))
}

# Plot normal Q-Q visualization for residuals
plot_qq <- function(model_list, xval, yname, filter = 'TRUE') {
  resids <- calc_resids(model_list, xval, yname)
  # In-sample Q-Q plot with standardized residuals
  insample <- resids$insample %>% mutate(st.resid = residuals/sd(residuals)) %>% filter_(filter) %>%
    ggplot(aes(sample = st.resid, color = factor(model))) +
    geom_qq(alpha = .05) +
    geom_qq_line() +
    labs(title = 'In-sample Q-Q plot with standardized residuals'
         , color = 'cross-validation sample')
  # Out-of-sample Q-Q plot
  outsample <- resids$outsample %>% mutate(st.resid = residuals/sd(residuals)) %>% filter_(filter) %>%
    ggplot(aes(sample = st.resid, color = factor(model))) +
    geom_qq(alpha = .05) +
    geom_qq_line() +
    labs(title = 'Out-of-sample Q-Q plot with standardized residuals'
         , color = 'cross-validation sample')
  return(list(insample = insample, outsample = outsample))
}
```

# Campaign linear models

## Cultivation score predictors {#campaign-cultivation-score-predictors}

Regress campaign giving against each of the cultivation score predictors.

```{r}
# List to store campaign linear models
clms <- list()
for(i in 1:length(xval_inds)) {
  # Create linear model excluding the holdout and out-of-sample indices
  clms[[i]] <- mdat %>%
    filter(row_number(CULTIVATION_SCORE) %nin% c(oos_inds, xval_inds[[i]])) %>%
    lm(
      log10plus1(CAMPAIGN_NEWGIFT_CMIT_CREDIT) ~
        ACTIVE_PROPOSALS +
        AGE +
        PM_VISIT_LAST_2_YRS +
        VISITS_5PLUS +
        AF_25K_GIFT +
        GAVE_IN_LAST_3_YRS +
        MG_250K_PLUS +
        PRESIDENT_VISIT +
        TRUSTEE_OR_ADVISORY_BOARD +
        Alumnus +
        DEEP_ENGAGEMENT +
        CHICAGO_HOME
      , data = .
    )
}
```

The full (and hard to read) results for each model are in the [appendix](#appendix-campaign-cultivation).

We can extract a few parameters of interest.

```{r}
plot_r2(clms) +
  geom_text(y = seq(10, 100, length.out = k - 1), label = 1:(k - 1), color = 'blue') +
  xlim(c(.45, .48))
```

The average $r^2 =$ `r lapply(clms, function(x) {summary(x)$r.squared}) %>% unlist() %>% mean() %>% round(3) %>% I()` is quite a good result.

```{r, fig.height = 6}
plot_coefs(clms)
```

```{r, rows.print = 100}
p.sig <- 1E-2
coef_pm_table(clms, p.sig)
```

The coefficients are extremely tightly clustered within each cross-validation set. Interestingly, age and alumni status both have negative coefficients. All are significant at $p =$ `r p.sig %>% I()`.

Here are the actual prediction MSEs:

```{r}
plot_mses(clms, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')
```

As usual, in-sample performance is moderately optimistic.

```{r}
plot_resids(clms, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')$insample +
  scale_y_continuous(breaks = seq(-10, 10, by = 2))
```

```{r}
plot_resids(clms, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')$outsample +
  scale_y_continuous(breaks = seq(-10, 10, by = 2))
```

At first glance, the linear trend evident in these results is concerning. Upon second glance, while still sobering it really just reinforces what we'd observed in the first of the two plots in the [Background](#background) section: campaign giving is decidedly nonlinear as cultivation scores approach their high/low limits. As seen above, the underlying factors should be transformed, and possibly modeled nonlinearly (splines).


```{r}
plot_qq(clms, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')$insample +
  scale_y_continuous(breaks = seq(-10, 10, by = 2))
```

```{r}
plot_qq(clms, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')$outsample +
  scale_y_continuous(breaks = seq(-10, 10, by = 2))
```

The quantile-quantile plot further illustrates the issue. The drift above the reference line to the left and below it to the right suggests less density than expected in the tails, which follows given that the range is bound -- it's not possible to give less than a nondonor or (for practical purposes) more than a 9-figure donor.

The story is completely different when looking only at those who actually gave:


```{r}
plot_qq(clms, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', filter = 'truth > 0')$insample +
  scale_y_continuous(breaks = seq(-10, 10, by = 2))
```


```{r}
plot_qq(clms, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', filter = 'truth > 0')$outsample +
  scale_y_continuous(breaks = seq(-10, 10, by = 2))
```

This is quite a bit nicer, suggesting only slight skewness in the tails.

**Takeaway.** When modeling giving amounts in the future, consider fitting a conditional model. Something along the lines of:

$$ E(\text{giving amount} ~ | ~ \text{donor status} = 1) $$

## All predictors 1 {#campaign-all-predictors-1}

The second model compares the variables underlying each PG score indicator, plus supplemental predictors. The first model incudes everything and I'll prune from there using MSE. Initial spline df are fairly arbitrary.

```{r}
# List to store campaign linear models
clmaps <- list()
for(i in 1:length(xval_inds)) {
  # Create linear model excluding the holdout and out-of-sample indices
  clmaps[[i]] <- mdat %>%
    filter(row_number(CULTIVATION_SCORE) %nin% c(oos_inds, xval_inds[[i]])) %>%
    lm(
      log10plus1(CAMPAIGN_NEWGIFT_CMIT_CREDIT) ~
        ACTIVE_PROPOSALS +
        ns(NUMERIC_AGE, df = 5) + # Underlying variable to AGE indicator
        PM_VISIT_LAST_2_YRS +
        log10plus1(VISIT_COUNT) + # Underlying VISITS_5PLUS indicator
        AF_25K_GIFT +
        sqrt(YEARS_OF_GIVING) + # Underlying GAVE_IN_LAST_3_YRS
        ns(YEARS_OF_GIVING_LAST_3, df = 2) + # Underlying GAVE_IN_LAST_3_YRS
        MG_250K_PLUS + # Decided to leave as factor
        PRESIDENT_VISIT +
        TRUSTEE_OR_ADVISORY_BOARD +
        Alumnus +
        DOUBLE_ALUM + # Deep Engagement component
        EVER_PARENT + # Deep Engagement component
        ns(SEASON_TICKET_YEARS, df = 1) + # Deep Engagement component
        CHICAGO_HOME +
        QUAL_LEVEL +
        AFFINITY_SCORE +
        MG_PR_MODEL_DESC
      , data = .
    )
}
```

Full results are in the [appendix](#appendix-campaign-all-predictors-1).

```{r}
plot_r2(clmaps) +
  geom_text(y = seq(10, 150, length.out = k - 1), label = 1:(k-1), color = 'blue') +
  xlim(c(.72, .735))
```

This is a much higher $r^2$ than seen above, but the model also includes many more predictors. Consider the MSE.

```{r}
plot_mses(clmaps, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')
```

Well, that's pretty conclusive -- this is also much lower than that seen previously. This implies that on average the predicted giving amount is less than a factor of 10 off. Which predictors contribute to the performance?

```{r, fig.height = 6}
plot_coefs(clmaps)
```

```{r, rows.print = 100}
coef_pm_table(clmaps, p.sig)
```

After accounting for the other variables, things that don't seem to matter include active proposals, Chicago home address, two of the deep engagement indicators, president visits, qualification level (inconsistent), and committee participation. Note that the "Future Prospect" factor level only appears 9 times -- one of the cross-validation samples must not have had anyone rated at that level. Additionally, some of these are likely already included in the affinity score.

```{r}
plot_resids(clmaps, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')$outsample +
  scale_y_continuous(breaks = seq(-10, 10, by = 2))
```

```{r}
plot_qq(clmaps, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')$outsample 
```

This already looks a lot nicer than the [Cultivation score predictors](#campaign-cultivation-score-predictors) model! Now let's try again, dropping the less-interesting predictors.

## All predictors 2 {#campaign-all-predictors-2}

Full results are in the [appendix](#appendix-campaign-all-predictors-2).

```{r}
# List to store campaign linear models
clmaps2 <- list()
for(i in 1:length(xval_inds)) {
  # Create linear model excluding the holdout and out-of-sample indices
  clmaps2[[i]] <- mdat %>%
    filter(row_number(CULTIVATION_SCORE) %nin% c(oos_inds, xval_inds[[i]])) %>%
    lm(
      log10plus1(CAMPAIGN_NEWGIFT_CMIT_CREDIT) ~
        ns(NUMERIC_AGE, df = 5) + # Underlying variable to AGE indicator
        PM_VISIT_LAST_2_YRS +
        log10plus1(VISIT_COUNT) + # Underlying VISITS_5PLUS indicator
        AF_25K_GIFT +
        sqrt(YEARS_OF_GIVING) + # Underlying GAVE_IN_LAST_3_YRS
        ns(YEARS_OF_GIVING_LAST_3, df = 2) + # Underlying GAVE_IN_LAST_3_YRS
        MG_250K_PLUS + # Decided to leave as factor
        Alumnus +
        ns(SEASON_TICKET_YEARS, df = 1) + # Deep Engagement component
        AFFINITY_SCORE +
        MG_PR_MODEL_DESC
      , data = .
    )
}
```

```{r}
plot_mses(clmaps2, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')
```

That's a marginal increase in outsample MSE (`r calc_outsample_mse(clmaps, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT') %>% mean() %>% round(4)` vs. `r calc_outsample_mse(clmaps2, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT') %>% mean() %>% round(4)`, difference of `r scales::percent({calc_outsample_mse(clmaps2, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT') %>% mean()}/{calc_outsample_mse(clmaps, xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT') %>% mean()} - 1)`) with many fewer predictors.

```{r}
plot_coefs(clmaps2)
```

```{r, rows.print = 100}
coef_pm_table(clmaps2, p.sig)
```

The spline degrees of freedom for numeric age could be tweaked.

## All predictors splines test {#campaign-all-predictors-splines}

```{r}
splines_max <- 10
clmaps3 <- list()
for (s in 1:splines_max) {
  clmaps3[[s]] <- list()
  for(i in 1:length(xval_inds)) {
    # Create linear model excluding the holdout and out-of-sample indices
    clmaps3[[s]][[i]] <- mdat %>%
      filter(row_number(CULTIVATION_SCORE) %nin% c(oos_inds, xval_inds[[i]])) %>%
      lm(
        log10plus1(CAMPAIGN_NEWGIFT_CMIT_CREDIT) ~
          ns(NUMERIC_AGE, df = s) + # Underlying variable to AGE indicator
          PM_VISIT_LAST_2_YRS +
          log10plus1(VISIT_COUNT) + # Underlying VISITS_5PLUS indicator
          AF_25K_GIFT +
          sqrt(YEARS_OF_GIVING) + # Underlying GAVE_IN_LAST_3_YRS
          ns(YEARS_OF_GIVING_LAST_3, df = 2) + # Underlying GAVE_IN_LAST_3_YRS
          MG_250K_PLUS + # Decided to leave as factor
          Alumnus +
          ns(SEASON_TICKET_YEARS, df = 1) + # Deep Engagement component
          AFFINITY_SCORE +
          MG_PR_MODEL_DESC
        , data = .
      )
  }
}
```

Try different spline degrees of freedom for NUMERIC_AGE. Full results are in the [appendix](#appendix-campaign-all-predictors-splines).

Consider the distribution of MSEs for each model.

```{r}
# Calculate MSEs for each model
spline_mse <- foreach(s = 1:splines_max, .combine = rbind) %do% {
  mses <- calc_outsample_mse(clmaps3[[s]], xval_inds, 'CAMPAIGN_NEWGIFT_CMIT_CREDIT')
  data.frame(spline.df = s, xv_group = factor(1:(k-1)), mses)
}
```
```{r}
# Plot results
spline_mse %>%
  ggplot(aes(x = spline.df, y = mses)) +
  geom_point(aes(color = xv_group)) +
  geom_smooth() +
  scale_x_continuous(breaks = 1:splines_max, minor_breaks = NULL) +
  labs(x = 'spline df', y = 'MSE', color = 'cross-validation sample')
```

For practical purposes there's not much difference between the different choices. It looks like 4 or 5 is where the mean MSE levels out, so I'll stick with my initial choice.

## Comparison & thoughts



# Transaction linear models

## Cultivation score predictors

## All predictors

## Comparison & thoughts

# Appendix

## Campaign cultivation results {#appendix-campaign-cultivation}

[Back](#campaign-cultivation-score-predictors)

```{r}
lapply(clms, function(x) summary(x))
```

## Campaign all predictors 1 {#appendix-campaign-all-predictors-1}

[Back](#campaign-all-predictors-1)

```{r}
lapply(clmaps, function(x) summary(x))
```

## Campaign all predictors 2 {#appendix-campaign-all-predictors-2}

[Back](#campaign-all-predictors-2)

```{r}
lapply(clmaps2, function(x) summary(x))
```

## Campaign all predictors splines {#appendix-campaign-all-predictors-splines}

[Back](#campaign-all-predictors-splines)

```{r}
lapply(clmaps3
  , function(x) {
    lapply(x, function(y) summary(y))
  }
)
```

