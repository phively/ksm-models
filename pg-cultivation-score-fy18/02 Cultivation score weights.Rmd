---
title: "02 Cultivation score weights"
output:
  html_notebook:
    toc: TRUE
    toc_float:
      collapsed: FALSE
---

# Goal

Determine the extent to which each of the data elements related to the PG cultivation score (see [Ben Porter's Donor Cultivation Checklist](https://www.case.org/currents/x74757)) have impacted giving.

# Setup and datafile

```{r setup, message = FALSE, warning = FALSE}
library(tidyverse)
library(gridExtra)
library(e1071)
library(wranglR)
library(foreach)

# Functions adapted from previous analysis steps
source('code/functions.R')
```

The data file is generated with [this code](https://github.com/phively/ksm-models/blob/master/pg-cultivation-score-fy18/code/generate-data.R), adapted from the import data step of [01 Initial exploration.Rmd
](https://github.com/phively/ksm-models/blob/master/pg-cultivation-score-fy18/01%20Initial%20exploration.Rmd).

```{r}
filepath <- 'data/2018-07-26 PG scores for all active prospects.xlsx'
source('code/generate-data.R')
```

# Background

The following 12 items were able to be extracted from the database:

  * Alum or spouse of alum
  * Age
  * Chicago home address
  * Visited by prospect manager in last 2 years
  * 5+ total visits
  * Deep engagement (multiple family degrees, parent, season tickets, etc.)
  * High-level annual giving ($25K+)
  * High-level advisory board participation
  * Previous major gift ($250K+)
  * Meeting with president
  * Open proposal
  * Consistent donor (10+ years of giving, including 1+ of last 3)

Each counts as one point toward the cultivation score, which ranges from 0 to `r max(pool$CULTIVATION_SCORE) %>% I()`.

The context for this analysis is to look at how giving is related to the cultivation score. Consider the following two plots (replicated from [01 Initial exploration.Rmd
](https://github.com/phively/ksm-models/blob/master/pg-cultivation-score-fy18/01%20Initial%20exploration.Rmd)):

```{r, echo = FALSE, message = FALSE}
pool %>% filter(!is.na(CULTIVATION_SCORE) & CAMPAIGN_NEWGIFT_CMIT_CREDIT > 0) %>%
  scatterplotter(x = 'CULTIVATION_SCORE', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT'
    , color = 'MG_PR_MODEL_DESC', ytrans = 'log10', ylabels = scales::dollar) +
  scale_x_continuous(breaks = 0:18, minor_breaks = NULL) +
  labs(title = 'Cultivation score versus log10 campaign giving', x = 'PG cultivation score'
       , y = 'Campaign giving credit', color = 'MG prioritization model')
```

```{r, echo = FALSE, message = FALSE}
pool %>% filter(!is.na(CULTIVATION_SCORE)) %>%
  scatterplotter(x = 'CULTIVATION_SCORE', y = 'LARGEST_GIFT_OR_PAYMENT'
    , color = 'MG_PR_MODEL_DESC', ytrans = 'log10plus1', ylabels = scales::dollar) +
  scale_x_continuous(breaks = 0:18, minor_breaks = NULL) +
  labs(title = 'Cultivation score versus log10 largest gift', x = 'PG cultivation score'
       , y = 'Largest gift or pledge payment', color = 'MG prioritization model')
```

There is a nearly linear relationship between PG cultivation score and both campaign giving and an entity's largest gift or pledge payment. Fitting some sort of linear model will enhance our understanding of the various checklist items by estimating their relative impact.

# Data exploration

## Indicators

Look at how each of the factors are distributed.

```{r, rows.print = 100}
pool %>% select(
  ACTIVE_PROPOSALS, AGE, PM_VISIT_LAST_2_YRS, VISITS_5PLUS, AF_25K_GIFT, GAVE_IN_LAST_3_YRS, MG_250K_PLUS
  , PRESIDENT_VISIT, TRUSTEE_OR_ADVISORY_BOARD, Alumnus, DEEP_ENGAGEMENT, CHICAGO_HOME
) %>%
  gather('Variable', 'x', 1:12) %>%
  group_by(Variable) %>%
  summarise(pct.yes = mean(x), yes = sum(x), no = nrow(pool) - sum(x), n = nrow(pool)) %>%
  arrange(desc(pct.yes)) %>%
  mutate(pct.yes = scales::percent(pct.yes))
```

As expected, alumni status is far and away the leader. I'm a bit surprised that trustee and advisory board is as high as it is. MG and president visit are the least common factors. However, they still have hundreds of observations each so I don't see a reason to drop either.

## Underlying variables

Exploration of the underlying variables for the indicators (that were straightforward to compute). The blue lines indicate the mean, and the purple ones the median.

```{r}
# Function to produce a summary table, with higher order central moments
summary_moments <- function(x, name = NULL) {
  # Requires e1071 for the skewness and kurtosis functions
  suppressPackageStartupMessages(
    if (!require(e1071)) {
      stop('Requires installation of package e1071')
    }
  )
  # If no name passed use the name of x
  if (is.null(name)) {name <- quote(x) %>% deparse()}
  # Data frame to be returned
  data.frame(
    name = name
    , n = na.omit(x) %>% length()
    , min = min(x, na.rm = TRUE)
    , median = median(x, na.rm = TRUE)
    , mean = mean(x, na.rm = TRUE)
    , max = max(x, na.rm = TRUE)
    , sd = sd(x, na.rm = TRUE)
    , skewness = e1071::skewness(x, na.rm = TRUE)
    , kurtosis = e1071::kurtosis(x, na.rm = TRUE)
    , NAs = is.na(x) %>% sum()
  ) %>% return()
}

# Generic function to create histograms
histogrammer <- function(data, x, binwidth = 1, bins = NULL, color = NULL
                         , trans = 'identity', xbreak = waiver()) {
  vec <- paste0('data$', eval(x)) %>% parse(text = .) %>% eval()
  data %>%
    ggplot(aes_string(x = x, color = color)) +
    geom_histogram(binwidth = binwidth, bins = bins, alpha = .5) +
    geom_density(aes(y = ..count..), alpha = .5) +
    geom_vline(xintercept = mean(vec, na.rm = TRUE), color = 'blue', linetype = 'dashed') +
    geom_vline(xintercept = median(vec, na.rm = TRUE), color = 'purple', linetype = 'dotted') +
    scale_x_continuous(trans = trans, breaks = xbreak)
}
```

```{r}
pool %>% filter(!is.na(NUMERIC_AGE)) %>%
  histogrammer(x = 'NUMERIC_AGE', xbreak = seq(0, 200, by = 10)) +
  labs(title = 'Age')
```

```{r}
summary_moments(pool$NUMERIC_AGE, 'Age')
```

The age distribution is moderately right-skewed but looks fine. For a quick fix the NAs could be imputed as the group mean.

```{r}
pool %>%
  histogrammer(x = 'VISIT_COUNT') +
  labs(title = 'Visit count')
```

```{r}
summary_moments(pool$VISIT_COUNT, 'Visits')
```

It'd be sensible to transform the x axis or otherwise get rid of those outliers.

```{r}
pool %>%
  histogrammer(x = 'VISIT_COUNT', trans = 'sqrt', binwidth = NULL, bins = 200,
               xbreak = c(seq(0, 10, by = 2), seq(10, 100, by = 10), seq(100, 200, by = 20))) +
  labs(title = 'Sqrt visit, log10 count') +
  scale_y_continuous(trans = 'log10plus1', breaks = 10^(0:20))
```

Nearly a linear decrease in visit count on a log/sqrt scale - though I'm not sure how to interpret this.

```{r}
pool %>%
  histogrammer(x = 'YEARS_OF_GIVING') +
  labs(title = 'Years of giving')
```

```{r}
summary_moments(pool$YEARS_OF_GIVING, 'Total years of giving')
```

This looks fine. There are more loyal donors than I would've thought.

```{r}
pool %>%
  histogrammer(x = 'YEARS_OF_GIVING_LAST_3') +
  labs(title = 'Years of giving last 3')
```

```{r}
summary_moments(pool$YEARS_OF_GIVING_LAST_3, 'Years of giving out of last 3')
```

Mostly nondonors, unsurprisingly.

```{r}
pool %>%
  histogrammer(x = 'MG_250K_COUNT') +
  labs(title = 'Count of $250K+ major gifts') +
  scale_y_continuous(trans = 'log10plus1', breaks = 10^(0:5), labels = 10^(0:5))
```

```{r}
summary_moments(pool$MG_250K_COUNT, '$250K+ major gifts')
```

```{r, rows.print = 100}
pool %>% group_by(MG_250K_COUNT) %>% mutate(n = 1) %>%
  summarise(
    total = sum(n)
    , proportion = {sum(n) / nrow(pool)} %>% scales::percent()
  )
```

Extremely few people make a single $250K+ gift, much less multiple ones.

```{r}
pool %>%
  histogrammer(x = 'SEASON_TICKET_YEARS', xbreak = seq(0, 20, by = 2)) +
  labs(title = 'Years holding season tickets') +
  scale_y_continuous(trans = 'log10plus1', breaks = 10^(0:20))
```

```{r}
summary_moments(pool$SEASON_TICKET_YEARS, 'Years holding season tickets')
```

That jump at 10 years is odd. Perhaps season tickets have only been consistently tracked for about 10 years?

## Underlying variable scatterplots

```{r}
pool %>% filter(!is.na(NUMERIC_AGE)) %>%
  scatterplotter(x = 'NUMERIC_AGE', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(NUMERIC_AGE)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Age versus campaign giving')
```

```{r}
pool %>% filter(!is.na(NUMERIC_AGE)) %>%
  scatterplotter(x = 'NUMERIC_AGE', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(NUMERIC_AGE)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Age versus largest gift')
```

As usual, age is positively associated with giving. The outlier `r pool$NUMERIC_AGE %>% max(na.rm = TRUE) %>% I()`-year-old should probably be removed.

```{r}
max_age <- 110
pool %>% filter(NUMERIC_AGE <= max_age) %>%
  scatterplotter(x = 'NUMERIC_AGE', y = 'LARGEST_GIFT_OR_PAYMENT'
                 , color = 'MG_PR_MODEL_DESC', ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(NUMERIC_AGE)), color = 'blue', linetype = 'dashed') +
  labs(title = bquote('Age versus largest gift' ~ (age <= .(max_age)) ))
```

For visits, based on the above exploration visit count needs a transformation.

```{r}
pool %>%
  scatterplotter(x = 'VISIT_COUNT', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(VISIT_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Log-sqrt visit count versus campaign giving') +
  scale_x_sqrt()
```

```{r}
pool %>%
  scatterplotter(x = 'VISIT_COUNT', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(VISIT_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Log-sqrt visit count versus largest gift') +
  scale_x_sqrt()
```

```{r}
pool %>%
  scatterplotter(x = 'VISIT_COUNT', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(VISIT_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Log-log visit count versus campaign giving') +
  scale_x_continuous(trans = 'log10plus1', breaks = c(0, 1, 10, 50, 100, 150, 200))
```

```{r}
pool %>%
  scatterplotter(x = 'VISIT_COUNT', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(VISIT_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Log-log visit count versus largest gift') +
  scale_x_continuous(trans = 'log10plus1', breaks = c(0, 1, 10, 50, 100, 150, 200))
```

The log-log plots look quite good. Visits $\geq$ 100 are outliers, but at first glance don't appear influential on the log-log scale (easy to test with e.g. Cook's D).

```{r}
pool %>%
  scatterplotter(x = 'YEARS_OF_GIVING', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(YEARS_OF_GIVING)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Years of giving versus campaign giving') +
  scale_x_sqrt()
```

```{r}
pool %>%
  scatterplotter(x = 'YEARS_OF_GIVING', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(YEARS_OF_GIVING)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Years of giving versus largest gift') +
  scale_x_sqrt()
```

The square root transformation does well for campaign giving, but not as well for largest gift or payment.

```{r}
# Box-Cox test for transformations
boxcox_lambdas <- seq(-1, 1, by = .01)
boxcox_lm <- lm(I(LARGEST_GIFT_OR_PAYMENT + 1) ~ YEARS_OF_GIVING, data = pool) %>%
  MASS::boxcox(lambda = boxcox_lambdas, plotit = FALSE)
maxLL <- boxcox_lm$x[which(boxcox_lm$y == max(boxcox_lm$y))]

# Plot results
boxcox_lm %>%
  unlist() %>%
  matrix(nrow = length(boxcox_lambdas)) %>%
  data.frame() %>%
  select(x = X1, y = X2) %>%
  ggplot(aes(x = x, y = y)) +
  geom_line() +
  geom_vline(aes(xintercept = x[which(y == max(y))]), color = 'blue', linetype = 'dashed') +
  labs(title = 'Box-Cox analysis', x = expression(lambda), y = 'log Likelihood')
```

$\lambda =$ `r maxLL %>% I()` is pretty close to a log transformation.

```{r}
# Best Box-Cox transformation, adding 1 so the response variable is strictly positive
boxcoxbest_trans <- function(x) {
  scales::trans_new(
    'boxcoxbest'
    , transform = function(x) {(x + 1)^maxLL}
    , inverse = function(x) {(x + 1)^(1/maxLL)}
  )
}
```

```{r}
grid.arrange(
# Plot Box-Cox results
  pool %>%
    scatterplotter(x = 'YEARS_OF_GIVING', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                   , ytrans = 'log10plus1', ylabels = scales::dollar) +
    geom_vline(aes(xintercept = mean(YEARS_OF_GIVING)), color = 'blue', linetype = 'dashed') +
    labs(title = 'Years of giving versus campaign giving, Box-Cox transformation', y = 'Largest gift') +
    scale_x_continuous(trans = 'boxcoxbest', breaks = c(0, 10))
# Plot log10 results
  , pool %>%
    scatterplotter(x = 'YEARS_OF_GIVING', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                   , ytrans = 'log10plus1', ylabels = scales::dollar) +
    geom_vline(aes(xintercept = mean(YEARS_OF_GIVING)), color = 'blue', linetype = 'dashed') +
    labs(title = 'Years of giving versus campaign giving, log transformation', y = 'Largest gift') +
    scale_x_continuous(trans = 'log10plus1')
)
```

After all that neither look linear, though they do look nearly linear around the mean.

```{r}
pool %>% mutate(last_3_yrs = factor(YEARS_OF_GIVING_LAST_3)) %>%
  ggplot(aes(x = last_3_yrs, y = CAMPAIGN_NEWGIFT_CMIT_CREDIT, color = MG_PR_MODEL_DESC)) +
  geom_boxplot() +
  facet_grid(. ~ MG_PR_MODEL_DESC) +
  scale_y_continuous(trans = 'log10plus1', labels = scales::dollar, breaks = 10^(0:20)) +
  labs(title = 'Years of giving of last 3 versus campaign giving')
```

```{r}
pool %>% mutate(last_3_yrs = factor(YEARS_OF_GIVING_LAST_3)) %>%
  ggplot(aes(x = last_3_yrs, y = LARGEST_GIFT_OR_PAYMENT, color = MG_PR_MODEL_DESC)) +
  geom_boxplot() +
  facet_grid(. ~ MG_PR_MODEL_DESC) +
  scale_y_continuous(trans = 'log10plus1', labels = scales::dollar, breaks = 10^(0:20)) +
  labs(title = 'Years of giving of last 3 versus largest gift')
```

I see a main effect for campaign giving.

```{r}
pool %>%
  scatterplotter(x = 'MG_250K_COUNT', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(MG_250K_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Count of $250K+ gifts versus campaign giving') +
  scale_x_sqrt()
```

```{r}
pool %>%
  scatterplotter(x = 'MG_250K_COUNT', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(MG_250K_COUNT)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Count of $250K+ gifts versus campaign giving') +
  scale_x_sqrt()
```

As seen above, pretty much all of the observations are outliers. Might make sense to leave this one discretized.

```{r}
pool %>%
  scatterplotter(x = 'SEASON_TICKET_YEARS', y = 'CAMPAIGN_NEWGIFT_CMIT_CREDIT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(SEASON_TICKET_YEARS)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Season ticket years versus campaign giving') +
  scale_x_continuous(breaks = seq(0, 100, by = 2))
```

```{r}
pool %>%
  scatterplotter(x = 'SEASON_TICKET_YEARS', y = 'LARGEST_GIFT_OR_PAYMENT', color = 'MG_PR_MODEL_DESC'
                 , ytrans = 'log10plus1', ylabels = scales::dollar) +
  geom_vline(aes(xintercept = mean(SEASON_TICKET_YEARS)), color = 'blue', linetype = 'dashed') +
  labs(title = 'Season ticket years versus campaign giving') +
  scale_x_continuous(breaks = seq(0, 100, by = 2))
```

This looks fine.

## Data exploration takeaways

  * Missing age values can be imputed as mean age
  * The 113-year-old is an outlier
  * Visit count could use log transform
  * Years of giving could use sqrt transform
  * $250K+ gifts is a binary indicator

# Modeling ground rules

I'll outline some basic methodology in advance of modeling to try to account for [researcher degrees of freedom](http://journals.sagepub.com/doi/full/10.1177/0956797611417632).

As seen above, both campaign giving and largest lifetime gift have a strong linear relationship with the cultivation score, formulated as a 0 to `r max(pool$CULTIVATION_SCORE) %>% I()` point scale. Currently, all criteria count as a single point (equally weighted) but I suspect they impact actual giving behavior differently. I propose four models:

  1) Linear regression of campaign giving on cultivation score variables
  2) Linear regression of campaign on all available explanatory variables, essentially looking at the cultivation score variables controlling for the preexisting modeled scores
  3) Linear regression of largest cash transaction on cultivation score variables
  4) Linear regression of largest cash transaction on all available explanatory variables, again to control for the preexisting modeled scores

If a given explanatory variable has the same coefficient sign and similar nonzero magnitudes in all models, I'll take this as evidence of an association with giving behavior.

After withholding a random 20% of the data as a test set, I'll use ten-fold cross-validation to determine which variables should be included in each model. Model performance will be determined based on out-of-sample mean squared error, defined as usual:

$$ {\text{MSE}} = \frac{1}{n} \sum_{i=1}^{n} \left( Y_i - \hat{Y}_i \right)^2 $$

The 20% test set will be used to confirm the cross-validation results, and then final models will be constructed on the entire dataset for comparison.

## Data cleanup

First, perform some quick data clean-up.

```{r}
mdat <- pool %>% mutate(
  # Impute missing ages as mean age
  NUMERIC_AGE = case_when(
    !is.na(NUMERIC_AGE) ~ NUMERIC_AGE
    , TRUE ~ mean(NUMERIC_AGE, na.rm = TRUE)
  )
) %>% select(
  # Drop unhelpful fields
  -ID_NUMBER, -PROSPECT_ID, -PROSPECT_NAME, -NU_DEG, -NU_DEG_SPOUSE, -POTENTIAL_INTEREST_AREAS
  , -PREF_NAME_SORT, -MG_ID_MODEL_YEAR, -MG_ID_MODEL_DESC, -MG_PR_MODEL_YEAR, -MG_PR_MODEL_DESC
)
```

I'll use my `wranglR::KFoldXVal` function to create the cross-validation groups.

```{r}
k <- 11
# Create k groups: first is 20% of the data (prop = .2) and the others are equally sized
xval_inds <- pool %>% wranglR::KFoldXVal(k = k, prop = .2, seed = 12644)
oos_inds <- xval_inds[[1]]
xval_inds <- xval_inds[2:k]
# Results
c(list(oos_inds), xval_inds) %>% summary
```

Group 1 is the out-of-sample validation set, and the other `r {k - 1} %>% I()` will be used for cross-validation.

Finally, I'll create a quick function to compute MSE.

```{r}
calc_mse <- function(y, yhat) {
  mean(
    (y - yhat)^2, na.rm = TRUE
  )
}
```


# Campaign linear models

## Cultivation score predictors {#cultivation-score-predictors}

Regress campaign giving against each of the cultivation score predictors.

```{r}
# List to store campaign linear models
clms <- list()
for(i in 1:length(xval_inds)) {
  # Create linear model excluding the holdout and out-of-sample indices
  clms[[i]] <- mdat %>%
    filter(row_number(CULTIVATION_SCORE) %nin% c(oos_inds, xval_inds[[i]])) %>%
    lm(
      log10plus1(CAMPAIGN_NEWGIFT_CMIT_CREDIT) ~
        ACTIVE_PROPOSALS +
        AGE +
        PM_VISIT_LAST_2_YRS +
        VISITS_5PLUS +
        AF_25K_GIFT +
        GAVE_IN_LAST_3_YRS +
        MG_250K_PLUS +
        PRESIDENT_VISIT +
        TRUSTEE_OR_ADVISORY_BOARD +
        Alumnus +
        DEEP_ENGAGEMENT +
        CHICAGO_HOME
      , data = .
    )
}
```

The full (and hard to read) results for each model are in the [appendix](#campaign-full-results).

We can extract a few parameters of interest.

```{r}
data.frame(r.squared = lapply(clms, function(x) summary(x)$r.squared) %>% unlist()) %>%
  ggplot(aes(x = r.squared)) + 
  geom_density() +
  geom_text(y = seq(10, 100, by = 10), label = 1:10, color = 'blue') +
  geom_vline(aes(xintercept = mean(r.squared)), color = 'blue', linetype = 'dashed', alpha = .5) +
  geom_rug(color = 'blue') +
  xlim(c(.45, .48)) +
  labs(title = bquote('Density plot of' ~ r^2 ~ 'results, mean' ~
      .(lapply(clms, function(x) {summary(x)$r.squared}) %>% unlist() %>% mean() %>% round(3))
    )
    , x = bquote(r^2)
)
```

The average $r^2 =$ `r lapply(clms, function(x) {summary(x)$r.squared}) %>% unlist() %>% mean() %>% round(3) %>% I()` is quite a good result.

```{r, fig.width = 8}
clms_coefs <- foreach(i = 1:length(clms), .combine = 'rbind') %do% {
  tmp <- summary(clms[[i]])$coefficients
  data.frame(tmp) %>%
  mutate(
    variable = rownames(tmp)
    , model = i
  ) %>% select(
    model
    , variable
    , beta.hat = Estimate
    , SE = Std..Error
    , t.val = t.value
    , Pr.t = Pr...t..
  ) %>% return()
}
# Plot coefficient results
clms_coefs %>%
  ggplot(aes(x = variable, y = beta.hat, color = factor(model))) +
  geom_point() +
  geom_hline(yintercept = 0, alpha = .5) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.title.y = element_text(angle = 0, vjust = .5)) +
  labs(
    title = 'Coefficient estimates per cross-validation model'
    , y = bquote(hat(beta))
    , color = 'cross-validation sample'
  )
```

```{r, rows.print = 100}
p.sig <- 1E-3
# Coefficient + sign counts
clms_coefs %>%
  group_by(variable) %>%
  summarise(
    `+` = sum(sign(beta.hat) == 1 & Pr.t < p.sig)
    , `0` = sum(Pr.t >= p.sig)
    , `-` = sum(sign(beta.hat) < 0 & Pr.t < p.sig)
  )
```

The coefficients are extremely tightly clustered within each cross-validation set. Interestingly, age and alumni status both have negative coefficients. All are significant at $p =$ `r p.sig %>% I()`.

Here are the actual predictions:

```{r}
clms_preds <- list()
for (i in 1:length(clms)) {
  clms_preds[[i]] <- data.frame(
    model = i
    , preds = clms[[i]] %>% predict(newdata = mdat[xval_inds[[i]], ])
    , truth = mdat %>% filter(row_number(CULTIVATION_SCORE) %in% xval_inds[[i]]) %>% select(CAMPAIGN_NEWGIFT_CMIT_CREDIT) %>% unlist() %>% log10plus1()
  )
}
# Compute MSE
clms_preds %>% lapply(function(x) calc_mse(y = x$truth, yhat = x$preds)) %>% unlist() %>% data.frame(MSE = .) %>%
  ggplot(aes(x = MSE)) +
  geom_density() +
  geom_rug()
```

## All predictors

# Transaction linear models

## Cultivation score predictors

## All predictors

# Appendix

## Campaign full results {#campaign-full-results}

[Back](#cultivation-score-predictors)

```{r}
lapply(clms, function(x) summary(x))
```