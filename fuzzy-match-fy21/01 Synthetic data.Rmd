---
title: "01 Synthetic data"
output:
  html_notebook:
    code_folding: show
    toc: true
    toc_float: true
---

# Goals

Create a synthetic dataset to test fuzzy matching approaches. Ideally, I'd like to use some sort of generative approach: drawing from distributions of common individual names, U.S. cities weighted by population, top employers, common job titles, etc.

# Setup

```{r setup}
library(tidyverse)
library(readxl)
library(foreach)

# Hide the dplyr .groups message
options(dplyr.summarise.inform = FALSE)
```

# Data

  * Name frequency distribution data from [census.gov](https://www.census.gov/topics/population/genealogy/data/2010_surnames.html)
  * Top cities from [census.gov](https://www.census.gov/programs-surveys/popest/data/data-sets.html)
  * Street names adapted from [fivethirtyeight.com](https://fivethirtyeight.com/features/whats-the-most-common-street-name-in-america/)
  * Top employers from [wikipedia.org](https://en.wikipedia.org/wiki/List_of_largest_United_States%E2%80%93based_employers_globally)
  * Job titles based on [linkedin.com](https://www.linkedin.com/business/talent/blog/talent-strategy/fastest-growing-jobs-in-the-us) 2017 job growth statistics

```{r}
# Read in Excel data
name_first <- read_xlsx(path = 'data/Names_First_Top1000.xlsx')

name_last <- read_xlsx(path = 'data/Names_2010Census_Top1000.xlsx', skip = 1) %>%
  filter(
    !is.na(RANK)
  ) %>% mutate(
    SURNAME = str_to_title(SURNAME)
  )

city <- suppressMessages(
  read_xlsx(path = 'data/cities SUB-IP-EST2019-ANNRNK.xlsx', skip = 3)
  ) %>% filter(
    !is.na(Census)
  ) %>% rename(
    index = `...1`
    , City = `...2`
  ) %>% mutate(
    City = str_replace(City, ' (city|town|village)', '')
  )

street <- read_xlsx(path = 'data/streetnames_fivethirtyeight.xlsx', skip = 4) %>%
  mutate(
    STREET_NAME = str_replace(STREET_NAME, ',.*', '')
  )

employer <- read_xlsx(path = 'data/top_employers_wikipedia.xlsx')

job_title <- read_xlsx(path = 'data/job_growth_linkedin_2017.xlsx')
```

# Data generation process

```{r}
# Helper function to generate probabilities
get_p <- function(dat, name_col, n_col, top_n = NULL) {
  # ensym() allows me to use unquoted column names, as in dplyr
  name_col <- ensym(name_col)
  n_col <- ensym(n_col)
  # If top_n not provided, use entire dataframe
  top_n <- ifelse(is.null(top_n), nrow(dat), top_n)
  dat <- dat %>%
    head(top_n)
  # Create and return data frame
  data.frame(
    name = dat %>% select(!!name_col) %>% unlist()
    , count = dat %>% select(!!n_col) %>% unlist()
    , stringsAsFactors = FALSE
  ) %>% mutate(
    p = count / sum(dat %>% select(!!n_col) %>% unlist())
  ) %>% return()
}
```

```{r}
# Helper function to create list of probability tables
ptable_gen <- function(
  max_n = 100 # Maximum number of rows to use
) {
  # Frequency data list
  list(
    name_f = name_first %>% get_p(Name, `TOTAL 1880-2018`, max_n)
    , name_l = name_last %>% get_p(SURNAME, `FREQUENCY (COUNT)`, max_n)
    , addr_street = street %>% get_p(STREET_NAME, TOTAL_OCCURANCES, max_n)
    , addr_city = city %>% get_p(City, `2019`, max_n)
    , employer = employer %>% get_p(Employer, `Global number of Employees`, max_n)
    , job = job_title %>% get_p(Title, Rate, max_n)
  ) %>% return()
}
```

```{r}
print_debug <- function(message) {
  cat(paste0(as.character(message), collapse = ''), sep = '\n')
}

# Helper function to generate data
# Count of addresses and jobs are currently pulled from the uniform distribution; this could be
#   changed to something like a Poisson distribution
data_gen <- function(
  dataset
  , n # number of records to generate
  , addr_min = 0 # address count min
  , addr_max = 2 # address count max
  , addr_p_new = .3 # p new address in same city for a given record
  , street_min = 1 # street number min
  , street_max = 99 # street number max
  , job_min = 0 # job count min
  , job_max = 3 # job count max
  , job_p = .3 # p new job at same employer for a given record
  , seed = NULL
  , debug_addr = FALSE
  , debug_jobs = FALSE
) {
  # Reproducible seed
  set.seed(seed)
  # Sampler function
  p_sampler <- function(ptable_part, size = n) {
    ptable_part %>% with(
      sample(name, size = size, prob = p, replace = TRUE)
    )
  }
  # Generate a data frame using the above parameters
   ######## First and last name ########
  names <- data.frame(
    first_name = dataset$name_f %>% p_sampler(n)
    , last_name = dataset$name_l %>% p_sampler(n)
    , stringsAsFactors = FALSE
  )
  ######## Addresses ########
  # Random vector containing number of addresses to generate
  addr_n <- sample(addr_min:addr_max, size = n, replace = TRUE)
  ###DEBUG###
  if(debug_addr) {
    message('Generating addresses')
    c(sum(addr_n), ' generated') %>% print_debug()
  }
  # Preallocating the address data frame; ncol * 2 because we need street1-x and citystate1-x
  addresses <- matrix(data = NA, nrow = n, ncol = addr_max * 2) %>%
    data.frame()
  # Name address columns
  address_colnames <- foreach(i = 1:addr_max, .combine = c) %do% {
    c(
      paste0('street_', i)
      , paste0('city_state_', i)
    )
  }
  names(addresses) <- address_colnames
  # Preallocate address parts
  streetnums <- sample(street_min:street_max, size = sum(addr_n), replace = TRUE)
  streets <- dataset$addr_street %>% p_sampler(size = sum(addr_n))
  cities <- dataset$addr_city %>% p_sampler(size = sum(addr_n))
  ###DEBUG###
  if(debug_addr) {
    print(data.frame(streetnums, streets, cities))
  }
  # Start counter at 1
  current_line <- 1
  # Loop through records to be generated
  for(i in 1:n) {
    ###DEBUG###
    if(debug_addr) {
      message('====Next record====')
      c('i = ', i) %>% print_debug()
      c('addr_n = ', addr_n[i]) %>% print_debug()
    }
    # Check current addr_n; if 0 skip this row
    if(addr_n[i] == 0) {next}
    ###DEBUG###
    if(debug_addr) {
      c('Current line = ', current_line) %>% print_debug()
    }
    # Intialize addr_conc for the current record
    addr_conc <- NULL
    # Pull appropriate streetnums, streets, and cities and concatenate into one row
    # Iterate through the appropriate number of random address parts per person, based on addr_n
    for(j in 1:addr_n[i]) {
      ###DEBUG###
      if(debug_addr) {
        message('--Next address--')
      }
      # Same city with probability addr_p_new
      same_city <- runif(1) <= addr_p_new
      # c(123 streetname, city_state)
      addr <- c(
        paste(
          # 123 streetname
          streetnums[current_line]
          , streets[current_line]
        )
        # city_state
        , ifelse(
            # When same_city passed and this is not the person's first generated address
            same_city == TRUE & j > 1
            , cities[current_line - 1]
            # Otherwise pick a new city (could be same one randomly)
            , cities[current_line]
          )
      )
      ###DEBUG###
      if(debug_addr) {
        c('streetnum = ', streetnums[current_line]) %>% print_debug()
        c('streets = ', streets[current_line]) %>% print_debug()
        c('cities = ', cities[current_line]) %>% print_debug()
        if(j > 1) {
          c('same city = ', same_city) %>% print_debug()
        }
        if(same_city == TRUE & j > 1) {
          c('forced city = ', cities[current_line - 1]) %>% print_debug()
        }
      }
      # Add current address and increment counter
      addr_conc <- c(addr_conc, addr)
      current_line <- current_line + 1
    }
    ###DEBUG###
    if(debug_addr) {
      message('Inserting:')
      print(addr_conc)
    }
    # Insert row
    addresses[i, 1:length(addr_conc)] <- addr_conc
  }
  ######## Employment ########
  # Random vector containing number of jobs to generate
  jobs_n <- sample(job_min:job_max, size = n, replace = TRUE)
  ###DEBUG###
  if(debug_jobs) {
    message('Generating jobs')
    c(sum(jobs_n), ' generated') %>% print_debug()
  }
  # Preallocating the jobs data frame; ncol * 2 because we need job1-x and employer1-x
  jobs <- matrix(data = NA, nrow = n, ncol = job_max * 2) %>%
    data.frame()
  # Name jobs columns
  jobs_colnames <- foreach(i = 1:job_max, .combine = c) %do% {
    c(
      paste0('title_', i)
      , paste0('company_', i)
    )
  }
  names(jobs) <- jobs_colnames
  # Preallocate job parts
  titles <- dataset$job %>% p_sampler(size = sum(jobs_n))
  employers <- dataset$employer %>% p_sampler(size = sum(jobs_n))
  ###DEBUG###
  if(debug_jobs) {
    print(data.frame(titles, employers))
  }
  # Start counter at 1
  current_line <- 1
  # Loop through records to be generated
  for(i in 1:n) {
    ###DEBUG###
    if(debug_jobs) {
      message('====Next record====')
      c('i = ', i) %>% print_debug()
      c('jobs_n = ', jobs_n[i]) %>% print_debug()
    }
    # Check current jobs_n; if 0 skip this row
    if(jobs_n[i] == 0) {next}
    ###DEBUG###
    if(debug_jobs) {
      c('Current line = ', current_line) %>% print_debug()
    }
    # Intialize jobs_conc for the current record
    jobs_conc <- NULL
    # Pull appropriate titles and companies and concatenate into one row
    # Iterate through the appropriate number of random job parts per person, based on jobs_n
    for(j in 1:jobs_n[i]) {
      ###DEBUG###
      if(debug_jobs) {
        message('--Next job--')
      }
      # Same employer with probability job_p
      same_employer <- runif(1) <= job_p
      # c(title, employer)
      job <- c(
        titles[current_line]
        , ifelse(
            # When same_employer passed and this is not the person's first generated employer
            same_employer == TRUE & j > 1
            , employers[current_line - 1]
            # Otherwise pick a new employer (could be same one randomly)
            , employers[current_line]
          )
      )
      ###DEBUG###
      if(debug_jobs) {
        c('title = ', titles[current_line]) %>% print_debug()
        c('employer = ', employers[current_line]) %>% print_debug()
        if(j > 1) {
          c('same employer = ', same_employer) %>% print_debug()
        }
        if(same_employer == TRUE & j > 1) {
          c('forced employer = ', employers[current_line - 1]) %>% print_debug()
        }
      }
      # Add current address and increment counter
      jobs_conc <- c(jobs_conc, job)
      current_line <- current_line + 1
    }
    ###DEBUG###
    if(debug_jobs) {
      message('Inserting:')
      print(jobs_conc)
    }
    # Insert row
    jobs[i, 1:length(jobs_conc)] <- jobs_conc
  }
  # Combine results
  df_out <- cbind(names, addresses, jobs)
  # Set attributes so I can see what parameters were used later
  match.call.formals <- mget(
    names(formals())
    , sys.frame(sys.nframe())
  )
  attr(df_out, 'data_gen.call') <- match.call()
  attr(df_out, 'data_gen') <- as.list(match.call.formals)
  # Return results
  df_out %>%
    return()
}
```

## Error checking

```{r}
p <- ptable_gen(100)
```

```{r, rows.print = 20}
# Check address generation
data_gen(p, n = 5, addr_max = 3, seed = 11, debug_addr = TRUE)
```

```{r, rows.print = 20}
# Check address generation
data_gen(p, n = 5, addr_min = 1, addr_max = 2, addr_p_new = 1, seed = 101, debug_addr = TRUE)
```

```{r, rows.print = 20}
# Check job generation
data_gen(p, n = 5, seed = 222, debug_jobs = TRUE)
```

# Data scrambling process

```{r}
# Helper function to scramble data
# Per-string operations
string_scrambler <- function(
  string # data to scramble
  , operations = c('substitution', 'insertion', 'deletion', 'transposition') # name of
    # permissible operations
  , p = .01 # per-character probability of performing the operation
  , valid_repl = c(letters, LETTERS, ' ', '.', ',', 0:9)  # valid replacement characters for
    # relevant operations
  , seed = NULL # reproducible seed
  , debug = FALSE
  , verbose_debug = FALSE
) {
  # Constants
  string_len <- str_length(string)
  # Reproducible seed
  set.seed(seed)
  # Determine whether each character in string will have an operation performed
  scramble <- sample(c(TRUE, FALSE), size = string_len, prob = c(p, 1 - p), replace = TRUE)
  # Generate operations to perform
  ops <- rep(NA, times = sum(scramble))
  ops[scramble] <- sample(operations, size = sum(scramble), replace = TRUE)
  # Function to return a random character
  f_rand_char <- function(valid_repl = valid_repl, size = 1) {
    sample(valid_repl, size = size, replace = TRUE) %>%
      return()
  }
  # Substitution
  f_substitution <- function(input_char, valid_repl = valid_repl, size = 1) {
    f_rand_char(valid_repl = valid_repl, size = size) %>%
      return()
  }
  # Insertion (before current character)
  f_insertion <- function(input_char, valid_repl = valid_repl, size = 1) {
    f_rand_char(valid_repl = valid_repl, size = size) %>%
    paste0(input_char) %>%
        return()
  }
  # Deletion
  f_deletion <- function(input_char) {
    return('')
  }
  # Transposition (with previous character, if present)
  f_transposition <- function(input_char, prev_char) {
    input_char %>%
    paste0(prev_char) %>%
      return()
  }
  ###DEBUG###
  if(debug | verbose_debug) {
    message('====String scrambling initialization====')
    c('Input string: ', string) %>% print_debug()
    c('Length: ', string_len) %>% print_debug()
    message('====Scrambling operations====')
    c('Scrambling ', sum(scramble), ' characters') %>% print_debug()
    c('Per-character scramble: ', which(scramble) %>% paste(collapse = ' ')) %>% print_debug()
    c('Randomized operations: ', ops %>% paste(collapse = ' ')) %>% print_debug()
  }
  # If nothing to scramble, return original string
  if(sum(scramble) == 0) {
    return(string)
  }
  # Implement different operations across the string
  ###DEBUG###
  if(verbose_debug) {
      message('====Detailed scrambling====')
  }
  # String to hold output
  scrambled <- ''
  # Loop through the string
  scrambler <- for(i in 1:string_len) {
    input_char <- str_sub(string, i, i)
    ###DEBUG###
    if(verbose_debug) {
      message('--Next character--')
      c('Performing ', ops[i], ' at position: ', i, ' on character: ', input_char) %>%
        print_debug()
    }
    # If not doing anything to this character, skip
    if(scramble[i] == FALSE) {
      next_char <- input_char
      scrambled <- paste0(scrambled, next_char)
    } else if(ops[i] == 'transposition') {
    # Otherwise, perform one of the implemented operations
      # Transposition gets special treatment
      scrambled_len <- str_length(scrambled)
      scrambled_sub <- str_sub(scrambled, 1, scrambled_len - 1)
      prev_char <- str_sub(scrambled, scrambled_len, scrambled_len)
      next_char <- f_transposition(input_char, prev_char)
      ###DEBUG###
      if(verbose_debug) {
        c('Transposition stats:') %>% print_debug()
        c('Scrambled_len: ' , scrambled_len, ' ; Scrambled_sub: ', scrambled_sub) %>%
          print_debug()
        c('prev_char: ', prev_char, ' ; next_char: ', next_char)
      }
    } else {
      next_char <- case_when(
        ops[i] == 'substitution' ~ f_substitution(input_char, valid_repl)
        , ops[i] == 'insertion' ~ f_insertion(input_char, valid_repl)
        , ops[i] == 'deletion' ~ f_deletion(input_char)
        # Fallback
        , TRUE ~ input_char
      )
    }
    # If transposition was performed, need to be sure to delete the previous character
    if(is.na(ops[i])) {
      # Do nothing
    } else if(ops[i] == 'transposition') {
      scrambled <- paste0(
        scrambled_sub
        , next_char
      )
    } else {
      # Otherwise continue as normal
      scrambled <- paste0(scrambled, next_char)
    }
    ###DEBUG###
    if(verbose_debug) {
      c('Result: ', next_char) %>% print_debug()
      c('Current string: ', scrambled) %>% print_debug
    }
  }
  return(scrambled)
}
```

```{r}
# Helper function to scramble fields
# Per-record (row) operations
record_scrambler <- function(
  dataset # original dataset
  , row # row number to scramble
  , operations = c('deletion', 'replacement', 'swapping') # name of permissible operations
  , p = 0.01 # per-field probability of performing an operation
  , seed = NULL # reproducible seed
) {
  # Reproducible seed
  set.seed(seed)
  ### Define operations
  # Deletion
  f_deletion <- function(input_field) {
    return('')
  }
  # Replacement
  f_replacement <- function(input_field, fieldname, dataset) {
    # Create potential replacement data based on the parameters used in the initial dataset
    old_call <- attr(dataset, 'data_gen')
    # Generate only a single row, with no seed
    old_call$n <- 1
    old_call$seed <- NULL
    # Generate new data and return selected field
    do.call(data_gen, args = old_call) %>%
      select(fieldname) %>%
      return()
  }
  # Swapping (with previous record, if possible)
  f_swapping <- function(input_field) {
    
  }
  # Determine which records will have an operation performed
  # If nothing to scramble, return dataset
  # If not doing anything to this record, skip
  # Otherwise, perform one of the implemented operations
}
```

## Error checking

```{r, rows.print = 20}
# Check string scrambler
string_scrambler(
  string = 'Hello World!'
  , p = .5
  , seed = 777
  , verbose_debug = TRUE
)
```

```{r, rows.print = 20}
# Check string scrambler
string_scrambler(
  string = 'The quick brown FOX jumped over the Lazy Dog. 10 times!'
  , p = .2
  , seed = 123
  , verbose_debug = TRUE
)
```


# Data generation

```{r}
p <- ptable_gen(100)

data_10k <- data_gen(
  p
  , n = 10000
  , seed = 112358
  , addr_min = 
  , 
)
```

```{r}
# Check data
check_fname <- data_10k %>%
  group_by(first_name) %>%
  summarise(n = n()) %>%
  left_join(
    p$name_f %>% select(name, p) %>% rename(first_name = name)
    , by = 'first_name'
  ) %>%
  mutate(
    pct = n / sum(n)
    , delta = round(pct - p, 4)
    , delta_pct = round(delta/p, 4)
  ) %>%
  arrange(desc(n))

# Print results for top names
check_fname %>%
  mutate(
    across(
      .cols = p:delta_pct
      , .fns = scales::percent
    )
  ) %>%
  head(10) %>%
  print()

# Plot histogram for all names
check_fname %>%
  ggplot(aes(x = delta_pct)) +
  geom_histogram(binwidth = .025, alpha = .5)
```

The proportions all look fine.

# Data scrambling

```{r}
test_scramble <- data_10k %>% head(3)
for(i in 1:3) {
  for(j in 1:ncol(data_10k)) {
    if(is.na(data_10k[i, j])) {
      next
    }
    test_scramble[i, j] <- data_10k[i, j] %>% string_scrambler(p = .025)
  }
}

test_scramble == data_10k %>% head(3)

test_scramble
```

