---
title: "Annual Fund $10K Variable Screening"
output: html_notebook
---

# Goal

Explore variable correlations and importance with a variety of techniques using resuable R code.

One school of thought is to use feature extraction methods, e.g. PCA on numeric variables, but simplicity and interpretability are desirable for the baseline model.

# Setup

Load [required packages](https://github.com/phively/ksm-models/blob/master/af-10k-fy17/PACKAGES.txt) and scripts.

```{r load_packages}
source('scripts/load_packages.R')
source('scripts/parse_data.R')
```

Create the modeling data file. This relies on the [script](https://github.com/phively/ksm-models/blob/master/af-10k-fy17/scripts/parse_data.R) created during [data exploration](https://github.com/phively/ksm-models/blob/master/af-10k-fy17/01%20AF%2010K%20Model%20Data%20Exploration.Rmd).

```{r format_data}
dat <- parse_data('data/2017-12-21 AF 10K Model.csv')
```

Drop features that are not useful for modeling.

```{r modeling_data}
# Drop all character and date variables
keep <- lapply(dat, class) %>% unlist() %>% str_to_lower() %nin% c('character', 'date')
mdat <- dat[, keep]
remove(keep)
```

# Random forest variable importance

See e.g. [Sauve & Tuleau-Malot (2014)](https://hal-unice.archives-ouvertes.fr/hal-00551375/document). Define variable importance in a random forest as the change in MSE when permuting a given observation vector. One nice feature is that highly correlated variables should be similarly important.

```{r rf.feature, cache = TRUE}
# Sample rows
set.seed(64629)
samp <- sample_n(mdat, size = nrow(mdat)/5)

# Run Boruta algorithm
(rf.vars <- Boruta(
    y = samp$GAVE_10K
    , x = samp %>% select(-GAVE_10K)
    , seed = 13529
  )
)
```

Plot of results.

```{r rf.plot.function}
Borutadata <- function(boruta.results) {
  data.frame(Importance = boruta.results$ImpHistory) %>%
  gather('Variable', 'Importance') %>%
  # Remove Importance. from the front of every variable name
  mutate(Variable = gsub('Importance.', '', Variable)) %>%
  # Append decision to the data frame
  left_join(
    data.frame(
        Decision = boruta.results$finalDecision %>% relevel('Confirmed')
      , Variable = names(boruta.results$finalDecision)
    ) %>% mutate(Variable = as.character(Variable))
    , by = 'Variable'
  ) %>%
  # Label shadow variables Reference
  mutate(Decision = factor(Decision, levels = c(levels(Decision), 'Reference'))) %>%
  ReplaceValues(old.val = NA, new.val = 'Reference') %>%
  # Drop uninformative variables and -Inf rows
  filter(Variable != 'GIVING_MAX_CASH_AMT' & Importance != -Inf) %>%
  # Return results
  return()
}

Borutaplotter <- function(boruta.results, title = 'Variable importances under Boruta algorithm') {
  # Plot results
  ggplot(boruta.results, aes(x = reorder(Variable, Importance, FUN = median), y = Importance, fill = Decision)) +
    geom_boxplot(alpha = .3) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .3)
            , panel.grid.minor = element_line(linetype = 'dotted')) +
    scale_fill_manual(values = c('green', 'yellow', 'red', 'black')) +
    labs(title = title, x = 'Variable', y = 'Importance') %>%
    suppressMessages() %>%
  # Return results
  return()
}
```

```{r rf.plot, fig.width = 12, fig.height = 8}
Borutadata(rf.vars) %>%
  Borutaplotter(., title = 'Variable importances under Boruta algorithm (classification)')
```

Try a regression tree.

```{r rfr.feature, cache = TRUE}
# Run Boruta algorithm
(rfr.vars <- Boruta(
    y = samp$GIVING_MAX_CASH_AMT
    , x = samp %>% select(-GAVE_10K)
    , seed = 41812
  )
)
```

```{r rfr.plot, fig.width = 12, fig.height = 8}
Borutadata(rfr.vars) %>%
  Borutaplotter(., title = 'Variable importances under Boruta algorithm (regression)')
```

I find it *very* surprising that `EVALUATION_RATING` doesn't register under either model. On the classification model, 37 variables are above `shadowMax`; excluding the 12 dollar amount ones leaves 25.

## Recommendations

The dollar amount variables should probably not be included (endogenous); **consider separate "ever made a pledge" and "made a first-year pledge" indicators**.

# Correlation structure

```{r interesting.vars}
# Generate interesting vars above shadowMax
interesting.vars <- Borutadata(rf.vars) %>%
  mutate(Variable = factor(Variable)) %>%
  group_by(Variable) %>%
  summarise(median = median(Importance)) %>%
  mutate(Variable = as.character(Variable))
(interesting.vars <- interesting.vars %>%
  filter(median > {interesting.vars %>% filter(Variable == 'shadowMax') %>% select(median) %>% unlist()}) %>%
  arrange(desc(median)))
```

```{r mdat2}
mdat2 <- mdat %>%
  select(interesting.vars$Variable) %>%
  mutate(
      GIVING_PLEDGE_ANY = {GIVING_MAX_PLEDGE_AMT > 0} %>% factor()
    , GIVING_PLEDGE_FIRST_YR = {GIVING_FIRST_YEAR_PLEDGE_AMT > 0} %>% factor()
  ) %>%
  select(
      -GIVING_MAX_PLEDGE_AMT
    , -GIVING_FIRST_YEAR_PLEDGE_AMT
    , -NGC_PFY1
    , -NGC_PFY2
    , -NGC_PFY3
    , -NGC_PFY4
    , -NGC_PFY5
    , -CASH_PFY1
    , -CASH_PFY2
    , -CASH_PFY3
    , -CASH_PFY4
    , -CASH_PFY5
    , -GIVING_FIRST_YEAR_CASH_AMT
    , -FIRST_KSM_YEAR
  )
```

```{r corplotter}
corplotter <- function(numeric.data) {
  cors <- cor(numeric.data) %>% round(2)
  # Do not fill in diagonal
  diag(cors) <- NA
  # Plot results
  cors %>%
    melt(., na.rm = TRUE) %>%
    ggplot(aes(x = Var2, y = Var1, fill = value, label = value)) +
    geom_tile() +
    geom_text() +
    coord_fixed() +
    scale_fill_gradient2(low = 'blue', mid = 'white', high = 'red', limits = c (-1, 1)) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .3)) %>%
  # Return results
  return()
}
```

```{r num.cors}
mdat2[, lapply(mdat2, FUN = function(x) class(x) == 'numeric') %>% unlist()] %>%
  str()
```

```{r corrplot, fig.width = 8, fig.height = 8}
# Include only numeric columns
mdat2[, lapply(mdat2, FUN = function(x) class(x) == 'numeric') %>% unlist()] %>%
  corplotter()
```

**Nearly collinear**

* `GIVING_MAX_CASH_FY` and `GIVING_FIRST_YEAR`

Note that these both have many conciding 0 entries. `GIVING_MAX_CASH_YR` may be a better choice as it fills in `RECORD_YR` for nondonors (first year of highest cash amount of $0).

**Highly correlated**

* `GIFTS_FYS_SUPPORTED` and `GIFTS_CASH`
* `RECORD_YR` and `GIVING_MAX_CASH_YR`
* `GIFTS_ALLOCS_SUPPORTED` and `GIVING_MAX_CASH_FY`
* `GIFTS_ALLOCS_SUPPORTED` and `GIVING_FIRST_YEAR`
* `GIFTS_ALLOCS_SUPPORTED` and `GIFTS_FYS_SUPPORTED`

The velocity measures are nearly orthogonal to everything else.

```{r fac.cors}
mdat2[, lapply(mdat2, FUN = function(x) class(x) == 'factor') %>% unlist()] %>%
  str()
```

```{r corrplot.facs, fig.width = 8, fig.height = 8}
# Include only factors; convert levels to numbers for comparison
mdat2[, lapply(mdat2, FUN = function(x) class(x) == 'factor') %>% unlist()] %>%
  mutate_all(funs(as.numeric)) %>%
  corplotter()
```

**Highly correlated**

* `GIVING_PLEDGE_ANY` and `GIVING_PLEDGE_FIRST_YR`
* `HOUSEHOLD_COUNTRY` and `HOUSEHOLD_CONTINENT`
* `HAS_HOME_ADDR` and `HAS_HOME_PHONE`

Note that `HOUSEHOLD_COUNTRY` has 130 levels, so it's not suitable for conventional modeling. The others do measure distinct concepts.

## Recommendations

* Drop `GIVING_MAX_CASH_FY` and `GIVING_FIRST_YEAR`; the other numeric variables look ok.
* Drop `HOUSEHOLD_COUNTRY`

# LASSO

LASSO is a well-known shrinkage technique (e.g. [Tibshirani 1996](https://statweb.stanford.edu/~tibs/lasso/lasso.pdf)) that works well as a variable selection tool due to its L1 penalty term, which shrinks coefficients to 0.

$$ \underset{\beta}{\text{argmin}} \left\{ f(X, Y, \beta) \right\} \text{ subject to } \|\beta \|_{1} \leq t $$


