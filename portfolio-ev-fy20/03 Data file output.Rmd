---
title: "03 Data file output"
output:
  html_notebook:
    toc: TRUE
    toc_float:
      collapsed: FALSE
---

# Goal

Create a set of modeling-ready, time-sliced data files with featuretoolsR.

# Setup

```{r setup, message = FALSE, warning = FALSE}
library(tidyverse)
library(lubridate)
library(wranglR)
library(readxl)
library(foreach)
library(reticulate)
library(nanotime)
library(featuretoolsR)

source(file = 'code/featuretools helper functions.R')
```

# Load and check data

```{r, warning = FALSE}
data_dt <- '2020-04-08'
source(file = 'code/data xlsx import.R')
source(file = 'code/data cleanup.R')
source(file = 'code/data validation.R')
```

# Set up Python session

```{python}
import featuretools as ft
```

# Create chunked entity sets

```{r, message = FALSE}
n <- 4
# Chunk the data into n (approximately) equal-sized bins
catracks_chunked <- chunk_datalist(
  catracks
  , master_table_name = 'households'
  , master_idx_name = 'HOUSEHOLD_ID'
  , chunks = n
  , seed = 123
)
```

```{r}
cutoff_dt <- ymd('20180831')
n_interesting_values <- 6L

entities_fy18 <- foreach(
  i = 1:length(catracks_chunked)
  , .combine = list
  , .multicombine = TRUE) %do% {
    # Create entityset
    a <- catracks_chunked[[i]] %>%
      entityset_create(
        entityset_name = paste0('chunk', i)
        , cutoff_dt = cutoff_dt
        , master_entity = 'households'
        , master_idx = 'HOUSEHOLD_ID'
        , debug = TRUE
      )
    # Insert interesting values
    a$add_interesting_values(max_values = n_interesting_values)
    # Return result as a list item
    return(a)
  }
```

```{r}
foreach (i = 1:n) %do% {
  print(entities_fy18[[i]])
}
```

Comparing this to the full dataset:

```{r, message = FALSE}
catracks %>%
  entityset_create(
    entityset_name = paste0('chunk', i)
    , cutoff_dt = cutoff_dt
    , master_entity = 'households'
    , master_idx = 'HOUSEHOLD_ID'
    , debug = FALSE
  ) %>%
  print()
```

Each chunk does contain about `r (1/n) %>% scales::percent() %>% I()` of the total data, as expected.

# Full run

```{r, cache = TRUE}
# Full run (slow)
dfs_output_fy18_1 <- entities_fy18[[1]] %>%
  dfs(
   target_entity = 'households'
   , agg_primitives = c('count', 'sum', 'std', 'mean', 'max', 'min', 'median', 'first', 'last', 'percent_true')
   , trans_primitives = c('cum_sum', 'cum_max', 'month', 'year', 'subtract_numeric', 'divide_numeric', 'time_since_previous')
   , max_depth = 2
   , verbose = TRUE
)

save('dfs_output_fy18_1', file = 'data/output/dfs_output_fy18_1.Rdata')
```

```{r, cache = TRUE}
# Full run (slow)
dfs_output_fy18_2 <- entities_fy18[[2]] %>%
  dfs(
   target_entity = 'households'
   , agg_primitives = c('count', 'sum', 'std', 'mean', 'max', 'min', 'median', 'first', 'last', 'percent_true')
   , trans_primitives = c('cum_sum', 'cum_max', 'month', 'year', 'subtract_numeric', 'divide_numeric', 'time_since_previous')
   , max_depth = 2
   , verbose = TRUE
)

save('dfs_output_fy18_2', file = 'data/output/dfs_output_fy18_2.Rdata')
```

```{r, cache = TRUE}
# Full run (slow)
dfs_output_fy18_3 <- entities_fy18[[3]] %>%
  dfs(
   target_entity = 'households'
   , agg_primitives = c('count', 'sum', 'std', 'mean', 'max', 'min', 'median', 'first', 'last', 'percent_true')
   , trans_primitives = c('cum_sum', 'cum_max', 'month', 'year', 'subtract_numeric', 'divide_numeric', 'time_since_previous')
   , max_depth = 2
   , verbose = TRUE
)

save('dfs_output_fy18_3', file = 'data/output/dfs_output_fy18_3.Rdata')
```

```{r, cache = TRUE}
# Full run (slow)
dfs_output_fy18_4 <- entities_fy18[[4]] %>%
  dfs(
   target_entity = 'households'
   , agg_primitives = c('count', 'sum', 'std', 'mean', 'max', 'min', 'median', 'first', 'last', 'percent_true')
   , trans_primitives = c('cum_sum', 'cum_max', 'month', 'year', 'subtract_numeric', 'divide_numeric', 'time_since_previous')
   , max_depth = 2
   , verbose = TRUE
)

save('dfs_output_fy18_4', file = 'data/output/dfs_output_fy18_4.Rdata')
```

# Combine output files into one dataframe

```{r}
# First two data frames
load('data/output/dfs_output_fy18_1.Rdata')
load('data/output/dfs_output_fy18_2.Rdata')

dfs_output_fy18_full1 <- bind_rows(
  dfs_output_fy18_1[[1]]
  , dfs_output_fy18_2[[1]]
)

save('dfs_output_fy18_full1', file = 'data/output/dfs_output_fy18_full1.Rdata')

remove(dfs_output_fy18_1, dfs_output_fy18_2)
```

```{r}
# Third and fourth data frames
load('data/output/dfs_output_fy18_3.Rdata')
load('data/output/dfs_output_fy18_4.Rdata')

dfs_output_fy18_full2 <- bind_rows(
  dfs_output_fy18_3[[1]]
  , dfs_output_fy18_4[[1]]
)

save('dfs_output_fy18_full2', file = 'data/output/dfs_output_fy18_full2.Rdata')

remove(dfs_output_fy18_3, dfs_output_fy18_4)
```

```{r}
load('data/output/dfs_output_fy18_full1.Rdata')
load('data/output/dfs_output_fy18_full2.Rdata')
```

Check for conflicting fields.

```{r}
names1 <- dfs_output_fy18_full1 %>% names()
names2 <- dfs_output_fy18_full2 %>% names()

which(names1 %nin% names2)
which(names2 %nin% names1)
```

Create full list of fields.

```{r}
dfs_output_fy18 <- bind_rows(
  dfs_output_fy18_full1[1, ]
  , dfs_output_fy18_full2[1, ]
)
dfs_output_fy18 <- dfs_output_fy18 %>% head(0)
```

Merge output into list of fields.

```{r}
dfs_output_fy18_full1 <- bind_rows(
  dfs_output_fy18
  , dfs_output_fy18_full1
)

save('dfs_output_fy18_full1', file = 'data/output/dfs_output_fy18_full1.Rdata')
```

```{r}
remove(dfs_output_fy18_full1)
gc()
```


```{r}
dfs_output_fy18_full2 <- bind_rows(
  dfs_output_fy18
  , dfs_output_fy18_full2
)

save('dfs_output_fy18_full2', file = 'data/output/dfs_output_fy18_full2.Rdata')
```

```{r}
remove(dfs_output_fy18_full2)
gc()
```

```{r}
load('data/output/dfs_output_fy18_full1.Rdata')
load('data/output/dfs_output_fy18_full2.Rdata')
```

```{r}
# Use pagefile
utils::memory.limit(128000)

dfs_output_fy18 <- rbind(
  dfs_output_fy18_full1
  , dfs_output_fy18_full2
)

save('dfs_output_fy18', file = 'data/output/dfs_output_fy18.Rdata')
```

```{r}
remove(dfs_output_fy18_full1, dfs_output_fy18_full2)
gc()
```

